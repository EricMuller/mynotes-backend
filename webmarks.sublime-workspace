{
	"auto_complete":
	{
		"selected_items":
		[
			[
				"web",
				"webmarks"
			],
			[
				"bo",
				"bookmark	statement"
			],
			[
				"B",
				"Bookmark"
			],
			[
				"get_",
				"get_object_or_404	function"
			],
			[
				"re",
				"resolvePath	function"
			],
			[
				"st",
				"store	function"
			],
			[
				"F",
				"FileStore	class"
			],
			[
				"serial",
				"serializers	module"
			],
			[
				"ser",
				"serializers	module"
			],
			[
				"book",
				"Bookmark"
			],
			[
				"a",
				"adapter	module"
			],
			[
				"so",
				"socialaccount"
			],
			[
				"lin",
				"linkedin"
			],
			[
				"ge",
				"get_object_or_404"
			],
			[
				"vi",
				"viewsets	module"
			],
			[
				"filter",
				"filter_class"
			],
			[
				"redonly",
				"read_only"
			],
			[
				"crea",
				"create"
			],
			[
				"pa",
				"parse"
			],
			[
				"NOe",
				"None	instance"
			],
			[
				"p",
				"parse_dl	function"
			],
			[
				"cre",
				"create"
			],
			[
				"STATIC",
				"STATIC_URL"
			],
			[
				"loa",
				"loads	function"
			],
			[
				"c",
				"channels	module"
			],
			[
				"m",
				"mynotes	module"
			],
			[
				"user",
				"user_cre"
			],
			[
				"archive",
				"ArchiveSerializer	class"
			],
			[
				"h",
				"html"
			],
			[
				"my",
				"my_object	statement"
			],
			[
				"page",
				"page_url	forstmt"
			],
			[
				"ROOT",
				"ROOT_DIR"
			],
			[
				"No",
				"not	keyword"
			],
			[
				"i",
				"ipdb	ipdb debug tool"
			],
			[
				"max",
				"max_count	statement"
			],
			[
				"auth",
				"authentification	module"
			],
			[
				"remove",
				"removeClass"
			],
			[
				"bored",
				"border-left-color"
			],
			[
				"padd",
				"padding-top"
			],
			[
				"next",
				"next_url"
			],
			[
				"fi",
				"filename	param"
			],
			[
				"pat",
				"pathBuilder	param"
			],
			[
				"path",
				"pathBuilder"
			],
			[
				"on",
				"onclick	Attr"
			],
			[
				"table",
				"table_note"
			],
			[
				"MA",
				"margin-bottom"
			],
			[
				"no",
				"note	statement"
			],
			[
				"o",
				"objects"
			],
			[
				"form",
				"formset	statement"
			],
			[
				"da",
				"dataSet	statement"
			],
			[
				"ma",
				"margin-top"
			],
			[
				"roo",
				"rootPath"
			],
			[
				"root",
				"rootPath	statement"
			],
			[
				"get",
				"get_default_type	function"
			],
			[
				"Dr",
				"DriveConstants	class"
			],
			[
				"dr",
				"DriveConstants	class"
			],
			[
				"con",
				"constants"
			],
			[
				"dta",
				"data_type	statement"
			],
			[
				"Se",
				"serializers"
			],
			[
				"Mo",
				"ModelAdmin	class"
			],
			[
				"repo",
				"repository	statement"
			],
			[
				"pro",
				"protocol"
			],
			[
				"la",
				"lazy	param"
			],
			[
				"getR",
				"getRepositories"
			],
			[
				"D",
				"DriveNode	class"
			],
			[
				"ba",
				"backdrive"
			],
			[
				"fold",
				"folders"
			],
			[
				"b",
				"_build"
			],
			[
				"g",
				"get"
			],
			[
				"crete",
				"createChild"
			],
			[
				"creat",
				"createRoot"
			],
			[
				"node",
				"nodeSelected"
			],
			[
				"folder",
				"folderId	statement"
			],
			[
				"parent",
				"parent_id"
			],
			[
				"par",
				"parent_id"
			],
			[
				"name",
				"name3"
			],
			[
				"log",
				"loginSvc"
			],
			[
				"up",
				"updateGlobals"
			],
			[
				"Login",
				"loginSvc"
			],
			[
				"is",
				"is_valid"
			],
			[
				"pla",
				"planSvc"
			],
			[
				"FOld",
				"Folders	class"
			],
			[
				"cont",
				"contentType	param"
			],
			[
				"conte",
				"contentType"
			],
			[
				"sc",
				"script"
			],
			[
				"in",
				"include"
			],
			[
				"code",
				"code_id"
			]
		]
	},
	"buffers":
	[
		{
			"file": "apps/webmarks/storage/models.py",
			"settings":
			{
				"buffer_size": 763,
				"line_ending": "Unix"
			}
		},
		{
			"file": "apps/webmarks/storage/serializers.py",
			"settings":
			{
				"buffer_size": 300,
				"line_ending": "Unix"
			}
		},
		{
			"file": "apps/webmarks/bookmarks/viewsets.py",
			"settings":
			{
				"buffer_size": 6065,
				"line_ending": "Unix"
			}
		},
		{
			"file": "apps/webmarks/storage/viewsets.py",
			"settings":
			{
				"buffer_size": 2098,
				"line_ending": "Unix"
			}
		},
		{
			"file": "apps/webmarks/storage/urls.py",
			"settings":
			{
				"buffer_size": 383,
				"line_ending": "Unix"
			}
		},
		{
			"file": "env/lib/python3.5/site-packages/compressor/base.py",
			"settings":
			{
				"buffer_size": 14075,
				"line_ending": "Unix"
			}
		},
		{
			"file": "apps/webmarks/storage/storages.py",
			"settings":
			{
				"buffer_size": 1561,
				"line_ending": "Unix"
			}
		},
		{
			"contents": "Searching 8376 files for \"Archive\" (whole word)\n\n/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/viewsets.py:\n   20  import logging\n   21  \n   22: from webmarks.storage.models import Archive\n   23  from webmarks.storage.serializers import ArchiveSerializer\n   24  \n   ..\n  132      def store(self, request, pk):\n  133          \"\"\"\n  134:             Crawl and Archive the Url Bookmark Page.\n  135          \"\"\"\n  136          bookmark = self.get_object()\n  ...\n  142          # indexes = {\"title\": bookmark.title, \"url\": bookmark}\n  143          indexes = self.serializer_class(bookmark).data\n  144:         archive = Archive.create(\n  145              bookmark.uuid, crawler.content_type, crawler.html.encode())\n  146:         archive.save()\n  147  \n  148:         FileStore().store(str(archive.id), request.user.username,\n  149                            crawler.html.encode(), indexes)\n  150  \n  151:         bookmark.archive_id = archive.id\n  152          bookmark.save()\n  153:         serializer = ArchiveSerializer(archive)\n  154          return Response(serializer.data)\n  155  \n\n/home/webdev/work/python/mywebmarks-backend/apps/webmarks/storage/migrations/0001_initial.py:\n   15      operations = [\n   16          migrations.CreateModel(\n   17:             name='Archive',\n   18              fields=[\n   19                  ('id', models.UUIDField(primary_key=True, serialize=False)),\n\n/home/webdev/work/python/mywebmarks-backend/apps/webmarks/storage/migrations/0002_auto_20170825_1900.py:\n   15      operations = [\n   16          migrations.AlterField(\n   17:             model_name='archive',\n   18              name='id',\n   19              field=models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False),\n\n/home/webdev/work/python/mywebmarks-backend/apps/webmarks/storage/urls.py:\n    5  \n    6  apiRouter = routers.DefaultRouter()\n    7: apiRouter.register(r'archives', viewsets.ArchiveViewSet, base_name='archive')\n    8  \n    9  urlpatterns = [\n\n/home/webdev/work/python/mywebmarks-backend/apps/webmarks/storage/viewsets.py:\n   27      \"\"\"\n   28      retrieve:\n   29:         Return a Archive instance.\n   30  \n   31      list:\n   ..\n   33  \n   34      create:\n   35:         Create a new Archive.\n   36  \n   37      delete:\n   38:         Remove an existing Archive.\n   39  \n   40      partial_update:\n   41:         Update one or more fields on an existing Archive.\n   42  \n   43      update:\n   44:         Update a Archive.\n   45      \"\"\"\n   46  \n   ..\n   52  \n   53      def retrieve(self, request, pk, format=None):\n   54:         archive = get_object_or_404(models.Archive, pk=pk)\n   55          if request.accepted_renderer.format == 'html':\n   56:             return Response(archive.data)\n   57  \n   58:         serializer = self.serializer_class(archive)\n   59          response = Response(serializer.data)\n   60          response['Cache-Control'] = 'no-cache'\n   ..\n   64      def download(self, request, pk):\n   65          \"\"\"\n   66:             Download Archive File.\n   67          \"\"\"\n   68:         archive = get_object_or_404(models.DataStorage, pk=pk)\n   69  \n   70:         archive_name = FileStore().get_file_path(str(archive.id),\n   71                                                   request.user.username)\n   72  \n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/shutil.py:\n   61  \n   62  class ReadError(OSError):\n   63:     \"\"\"Raised when an archive cannot be read\"\"\"\n   64  \n   65  class RegistryError(Exception):\n   ..\n  595  \n  596      'owner' and 'group' can be used to define an owner and a group for the\n  597:     archive that is being built. If not provided, the current owner and group\n  598      will be used.\n  599  \n  ...\n  630      # creating the tarball\n  631      if logger is not None:\n  632:         logger.info('Creating tar archive')\n  633  \n  634      uid = _get_uid(owner)\n  ...\n  715  \n  716  def register_archive_format(name, function, extra_args=None, description=''):\n  717:     \"\"\"Registers an archive format.\n  718  \n  719      name is the name of the format. function is the callable that will be\n  ...\n  740  def make_archive(base_name, format, root_dir=None, base_dir=None, verbose=0,\n  741                   dry_run=0, owner=None, group=None, logger=None):\n  742:     \"\"\"Create an archive file (eg. zip or tar).\n  743  \n  744      'base_name' is the name of the file to create, minus any format-specific\n  745:     extension; 'format' is the archive format: one of \"zip\", \"tar\", \"bztar\"\n  746      or \"gztar\".\n  747  \n  748      'root_dir' is a directory that will be the root directory of the\n  749:     archive; ie. we typically chdir into 'root_dir' before creating the\n  750:     archive.  'base_dir' is the directory where we start archiving from;\n  751      ie. 'base_dir' will be the common prefix of all files and\n  752:     directories in the archive.  'root_dir' and 'base_dir' both default\n  753:     to the current directory.  Returns the name of the archive file.\n  754  \n  755:     'owner' and 'group' are used when creating a tar archive. By default,\n  756      uses the current owner and group.\n  757      \"\"\"\n  ...\n  772          format_info = _ARCHIVE_FORMATS[format]\n  773      except KeyError:\n  774:         raise ValueError(\"unknown archive format '%s'\" % format)\n  775  \n  776      func = format_info[0]\n  ...\n  831      `function` is the callable that will be\n  832      used to unpack archives. The callable will receive archives to unpack.\n  833:     If it's unable to handle an archive, it needs to raise a ReadError\n  834      exception.\n  835  \n  ...\n  860          import zipfile\n  861      except ImportError:\n  862:         raise ReadError('zlib not supported, cannot unpack this archive.')\n  863  \n  864      if not zipfile.is_zipfile(filename):\n  ...\n  926  \n  927  def unpack_archive(filename, extract_dir=None, format=None):\n  928:     \"\"\"Unpack an archive.\n  929  \n  930:     `filename` is the name of the archive.\n  931  \n  932:     `extract_dir` is the name of the target directory, where the archive\n  933      is unpacked. If not provided, the current working directory is used.\n  934  \n  935:     `format` is the archive format: one of \"zip\", \"tar\", or \"gztar\". Or any\n  936      other registered format. If not provided, unpack_archive will use the\n  937      filename extension and see if an unpacker was registered for that\n  ...\n  955          format = _find_unpack_format(filename)\n  956          if format is None:\n  957:             raise ReadError(\"Unknown archive format '{0}'\".format(filename))\n  958  \n  959          func = _UNPACK_FORMATS[format][1]\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/IPython/core/display.py:\n 1063          --------\n 1064  \n 1065:         Video('https://archive.org/download/Sita_Sings_the_Blues/Sita_Sings_the_Blues_small.mp4')\n 1066          Video('path/to/video.mp4')\n 1067          Video('path/to/video.mp4', embed=True)\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/IPython/core/magics/execution.py:\n  777              # %run.  As best I can see, this is NOT something IPython is doing\n  778              # at all, and similar problems have been reported before:\n  779:             # http://coding.derkeiler.com/Archive/Python/comp.lang.python/2004-10/0188.html\n  780              # Since this seems to be done by the interpreter itself, the best\n  781              # we can do is to at least restore __builtins__ for the user on\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/PIL/IcoImagePlugin.py:\n   16  # This plugin is a refactored version of Win32IconImagePlugin by Bryan Davis\n   17  # <casadebender@gmail.com>.\n   18: # https://code.google.com/archive/p/casadebender/wikis/Win32IconImagePlugin.wiki\n   19  #\n   20  # Icon format references:\n   ..\n  253      This plugin is a refactored version of Win32IconImagePlugin by Bryan Davis\n  254      <casadebender@gmail.com>.\n  255:     https://code.google.com/archive/p/casadebender/wikis/Win32IconImagePlugin.wiki\n  256      \"\"\"\n  257      format = \"ICO\"\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/PIL/JpegPresets.py:\n   63  `JpegImagePlugin.convert_dict_qtables(dict_qtables)` function.\n   64  \n   65: Libjpeg ref.: http://web.archive.org/web/20120328125543/http://www.jpegcameras.com/libjpeg/libjpeg-3.html\n   66  \n   67  \"\"\"\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/Twisted-17.1.0-py3.5-linux-x86_64.egg/twisted/python/modules.py:\n  450  \n  451      @ivar filePath: a FilePath-like object pointing at the filesystem location\n  452:     or archive file where this path entry is stored.\n  453  \n  454      @ivar pythonPath: a PythonPath instance.\n  ...\n  505          \"\"\"\n  506          Map the given FS path to a ZipPath, by looking at the ZipImporter's\n  507:         \"archive\" attribute and using it as our ZipArchive root, then walking\n  508:         down into the archive from there.\n  509  \n  510          @return: a L{zippath.ZipPath} or L{zippath.ZipArchive} instance.\n  511          \"\"\"\n  512:         za = ZipArchive(self.importer.archive)\n  513:         myPath = FilePath(self.importer.archive)\n  514          itsPath = FilePath(fsPathString)\n  515          if myPath == itsPath:\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/Twisted-17.1.0-py3.5-linux-x86_64.egg/twisted/python/test/test_zipstream.py:\n  153      def makeZipFile(self, contents, directory=''):\n  154          \"\"\"\n  155:         Makes a zip file archive containing len(contents) files.  Contents\n  156          should be a list of strings, each string being the content of one file.\n  157          \"\"\"\n  ...\n  188          \"\"\"\n  189          A zipfile entry with the wrong magic number should raise BadZipfile for\n  190:         readfile(), but that should not affect other files in the archive.\n  191          \"\"\"\n  192          fn = self.makeZipFile([\"test contents\",\n  ...\n  258          \"\"\"\n  259          L{twisted.python.zipstream.unzipIterChunky} returns an iterator which\n  260:         must be exhausted to completely unzip the input archive.\n  261          \"\"\"\n  262          numfiles = 10\n  ...\n  278          The path to which a file is extracted by L{zipstream.unzipIterChunky}\n  279          is determined by joining the C{directory} argument to C{unzip} with the\n  280:         path within the archive of the file being extracted.\n  281          \"\"\"\n  282          numfiles = 10\n  ...\n  333          \"\"\"\n  334          unzipIterChunky should unzip the given number of bytes per iteration on\n  335:         a stored archive.\n  336          \"\"\"\n  337          self._unzipIterChunkyTest(zipfile.ZIP_STORED, 500, 35, 45)\n  ...\n  341          \"\"\"\n  342          unzipIterChunky should unzip the given number of bytes per iteration on\n  343:         a deflated archive.\n  344          \"\"\"\n  345          self._unzipIterChunkyTest(zipfile.ZIP_DEFLATED, 972, 23, 27)\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/Twisted-17.1.0-py3.5-linux-x86_64.egg/twisted/python/zippath.py:\n   35      \"\"\"\n   36  \n   37:     def __init__(self, archive, pathInArchive):\n   38          \"\"\"\n   39          Don't construct me directly.  Use C{ZipArchive.child()}.\n   40  \n   41:         @param archive: a L{ZipArchive} instance.\n   42  \n   43          @param pathInArchive: a ZIP_PATH_SEP-separated string.\n   44          \"\"\"\n   45:         self.archive = archive\n   46          self.pathInArchive = pathInArchive\n   47  \n   ..\n   50          sep = _coerceToFilesystemEncoding(pathInArchive, ZIP_PATH_SEP)\n   51          archiveFilename = _coerceToFilesystemEncoding(\n   52:             pathInArchive, archive.zipfile.filename)\n   53          self.path = os.path.join(archiveFilename,\n   54                                   *(self.pathInArchive.split(sep)))\n   ..\n   58          if not isinstance(other, ZipPath):\n   59              return NotImplemented\n   60:         return cmp((self.archive, self.pathInArchive),\n   61:                    (other.archive, other.pathInArchive))\n   62  \n   63  \n   64      def __repr__(self):\n   65          parts = [_coerceToFilesystemEncoding(\n   66:             self.sep, os.path.abspath(self.archive.path))]\n   67          parts.extend(self.pathInArchive.split(self.sep))\n   68          ossep = _coerceToFilesystemEncoding(self.sep, os.sep)\n   ..\n   84          splitup = self.pathInArchive.split(self.sep)\n   85          if len(splitup) == 1:\n   86:             return self.archive\n   87:         return ZipPath(self.archive, self.sep.join(splitup[:-1]))\n   88  \n   89  \n   90      def child(self, path):\n   91          \"\"\"\n   92:         Return a new ZipPath representing a path in C{self.archive} which is\n   93          a child of this path.\n   94  \n   95          @note: Requesting the C{\"..\"} (or other special name) child will not\n   96              cause L{InsecurePath} to be raised since these names do not have\n   97:             any special meaning inside a zip archive.  Be particularly\n   98              careful with the C{path} attribute (if you absolutely must use\n   99              it) as this means it may include special names with special\n  100:             meaning outside of the context of a zip archive.\n  101          \"\"\"\n  102          joiner = _coerceToFilesystemEncoding(path, ZIP_PATH_SEP)\n  103          pathInArchive = _coerceToFilesystemEncoding(path, self.pathInArchive)\n  104:         return ZipPath(self.archive, joiner.join([pathInArchive, path]))\n  105  \n  106  \n  ...\n  114  \n  115      def isdir(self):\n  116:         return self.pathInArchive in self.archive.childmap\n  117  \n  118  \n  119      def isfile(self):\n  120:         return self.pathInArchive in self.archive.zipfile.NameToInfo\n  121  \n  122  \n  ...\n  128          if self.exists():\n  129              if self.isdir():\n  130:                 return list(self.archive.childmap[self.pathInArchive].keys())\n  131              else:\n  132                  raise UnlistableError(\n  ...\n  159      def open(self, mode=\"r\"):\n  160          pathInArchive = _coerceToFilesystemEncoding('', self.pathInArchive)\n  161:         return self.archive.zipfile.open(pathInArchive, mode=mode)\n  162  \n  163  \n  ...\n  173          \"\"\"\n  174          pathInArchive = _coerceToFilesystemEncoding(\"\", self.pathInArchive)\n  175:         return self.archive.zipfile.NameToInfo[pathInArchive].file_size\n  176  \n  177  \n  ...\n  179          \"\"\"\n  180          Retrieve this file's last access-time.  This is the same as the last access\n  181:         time for the archive.\n  182  \n  183          @return: a number of seconds since the epoch\n  184          \"\"\"\n  185:         return self.archive.getAccessTime()\n  186  \n  187  \n  ...\n  195          pathInArchive = _coerceToFilesystemEncoding(\"\", self.pathInArchive)\n  196          return time.mktime(\n  197:             self.archive.zipfile.NameToInfo[pathInArchive].date_time\n  198              + (0, 0, 0))\n  199  \n  ...\n  212  class ZipArchive(ZipPath):\n  213      \"\"\"\n  214:     I am a L{FilePath}-like object which can wrap a zip archive as if it were a\n  215      directory.\n  216  \n  ...\n  222      converting if required.\n  223      \"\"\"\n  224:     archive = property(lambda self: self)\n  225  \n  226      def __init__(self, archivePathname):\n  227          \"\"\"\n  228:         Create a ZipArchive, treating the archive at archivePathname as a zip\n  229          file.\n  230  \n  ...\n  253      def child(self, path):\n  254          \"\"\"\n  255:         Create a ZipPath pointing at a path within the archive.\n  256  \n  257          @param path: a L{bytes} or L{unicode} with no path separators in it\n  ...\n  263      def exists(self):\n  264          \"\"\"\n  265:         Returns C{True} if the underlying archive exists.\n  266          \"\"\"\n  267          return FilePath(self.zipfile.filename).exists()\n  ...\n  270      def getAccessTime(self):\n  271          \"\"\"\n  272:         Return the archive file's last access time.\n  273          \"\"\"\n  274          return FilePath(self.zipfile.filename).getAccessTime()\n  ...\n  277      def getModificationTime(self):\n  278          \"\"\"\n  279:         Return the archive file's modification time.\n  280          \"\"\"\n  281          return FilePath(self.zipfile.filename).getModificationTime()\n  ...\n  284      def getStatusChangeTime(self):\n  285          \"\"\"\n  286:         Return the archive file's status change time.\n  287          \"\"\"\n  288          return FilePath(self.zipfile.filename).getStatusChangeTime()\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/Twisted-17.1.0-py3.5-linux-x86_64.egg/twisted/python/zipstream.py:\n   30          if not self.fp:\n   31              raise RuntimeError(\n   32:                 \"Attempt to read ZIP archive that was already closed\")\n   33          zinfo = self.getinfo(name)\n   34  \n   ..\n   71      \"\"\"\n   72      Abstract superclass of both compressed and uncompressed variants of\n   73:     file-like objects within a zip archive.\n   74  \n   75      @ivar chunkingZipFile: a chunking zip file.\n   ..\n  277  \n  278      @param zipinfo: a C{zipfile.ZipInfo} instance describing an entry in a zip\n  279:     archive to be counted.\n  280  \n  281      @return: the number of chunks present in the zip file.  (Even an empty file\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/autobahn/websocket/protocol.py:\n 3477          # connection \"Upgrade\" header\n 3478          # See also:\n 3479:         # http://www.ietf.org/mail-archive/web/hybi/current/msg09841.html\n 3480          # http://code.google.com/p/chromium/issues/detail?id=148908\n 3481          #\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/boto/__init__.py:\n  582                 is_secure=False, **kwargs):\n  583      \"\"\"\n  584:     Connect to the Internet Archive via their S3-like API.\n  585  \n  586      :type ia_access_key_id: string\n  ...\n  595  \n  596      :rtype: :class:`boto.s3.connection.S3Connection`\n  597:     :return: A connection to the Internet Archive\n  598      \"\"\"\n  599      from boto.s3.connection import S3Connection\n  ...\n  606  \n  607      return S3Connection(access_key, secret_key,\n  608:                         host='s3.us.archive.org',\n  609                          calling_format=OrdinaryCallingFormat(),\n  610                          is_secure=is_secure, **kwargs)\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/boto/codedeploy/layer1.py:\n   77        respectively.\n   78      + Application revisions (also known simply as revisions ), which\n   79:       are archive files that are stored in Amazon S3 buckets or GitHub\n   80        repositories. These revisions contain source content (such as\n   81        source code, web pages, executable files, any deployment scripts,\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/boto/glacier/concurrent.py:\n   75  \n   76  class ConcurrentUploader(ConcurrentTransferer):\n   77:     \"\"\"Concurrently upload an archive to glacier.\n   78  \n   79:     This class uses a thread pool to concurrently upload an archive\n   80      to glacier using the multipart upload API.\n   81  \n   ..\n   95          :type part_size: int\n   96          :param part_size: The size, in bytes, of the chunks to use when uploading\n   97:             the archive parts.  The part size must be a megabyte multiplied by\n   98              a power of two.\n   99  \n  ...\n  109  \n  110      def upload(self, filename, description=None):\n  111:         \"\"\"Concurrently create an archive.\n  112  \n  113          The part_size value specified when the class was constructed\n  ...\n  121  \n  122          :type description: str\n  123:         :param description: The description of the archive.\n  124  \n  125          :rtype: str\n  126:         :return: The archive id of the newly created archive.\n  127  \n  128          \"\"\"\n  ...\n  147                                            total_parts)\n  148          except UploadArchiveError as e:\n  149:             log.debug(\"An error occurred while uploading an archive, \"\n  150                        \"aborting multipart upload.\")\n  151              self._api.abort_multipart_upload(self._vault_name, upload_id)\n  ...\n  166                  self._shutdown_threads()\n  167                  raise UploadArchiveError(\"An error occurred while uploading \"\n  168:                                          \"an archive: %s\" % result)\n  169              # Each unit of work returns the tree hash for the given part\n  170              # number, which we use at the end to compute the tree hash of\n  171:             # the entire archive.\n  172              part_number, tree_sha256 = result\n  173              hash_chunks[part_number] = tree_sha256\n  ...\n  268  class ConcurrentDownloader(ConcurrentTransferer):\n  269      \"\"\"\n  270:     Concurrently download an archive from glacier.\n  271  \n  272:     This class uses a thread pool to concurrently download an archive\n  273      from glacier.\n  274  \n  ...\n  280                   num_threads=10):\n  281          \"\"\"\n  282:         :param job: A layer2 job object for archive retrieval object.\n  283  \n  284          :param part_size: The size, in bytes, of the chunks to use when uploading\n  285:             the archive parts.  The part size must be a megabyte multiplied by\n  286              a power of two.\n  287  \n  ...\n  292      def download(self, filename):\n  293          \"\"\"\n  294:         Concurrently download an archive.\n  295  \n  296:         :param filename: The filename to download the archive to\n  297          :type filename: str\n  298  \n  ...\n  307              self._wait_for_download_threads(filename, result_queue, total_parts)\n  308          except DownloadArchiveError as e:\n  309:             log.debug(\"An error occurred while downloading an archive: %s\", e)\n  310              raise e\n  311          log.debug(\"Download completed.\")\n  ...\n  332                      raise DownloadArchiveError(\n  333                          \"An error occurred while uploading \"\n  334:                         \"an archive: %s\" % result)\n  335                  part_number, part_size, actual_hash, data = result\n  336                  hash_chunks[part_number] = actual_hash\n  ...\n  340                  f.flush()\n  341          final_hash = bytes_to_hex(tree_hash(hash_chunks))\n  342:         log.debug(\"Verifying final tree hash of archive, expecting: %s, \"\n  343                    \"actual: %s\", self._job.sha256_treehash, final_hash)\n  344          if self._job.sha256_treehash != final_hash:\n  345              self._shutdown_threads()\n  346              raise TreeHashDoesNotMatchError(\n  347:                 \"Tree hash for entire archive does not match, \"\n  348                  \"expected: %s, got: %s\" % (self._job.sha256_treehash,\n  349                                             final_hash))\n  ...\n  387      def _process_chunk(self, work):\n  388          \"\"\"\n  389:         Attempt to download a part of the archive from Glacier\n  390          Store the result in the result_queue\n  391  \n  ...\n  406      def _download_chunk(self, work):\n  407          \"\"\"\n  408:         Downloads a chunk of archive from Glacier. Saves the data to a temp file\n  409          Returns the part number and temp file location\n  410  \n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/boto/glacier/job.py:\n   64          This operation downloads the output of the job.  Depending on\n   65          the job type you specified when you initiated the job, the\n   66:         output will be either the content of an archive or a vault\n   67          inventory.\n   68  \n   69          You can download all the job output or download a portion of\n   70          the output by specifying a byte range. In the case of an\n   71:         archive retrieval job, depending on the byte range you\n   72          specify, Amazon Glacier returns the checksum for the portion\n   73          of the data. You can compute the checksum on the client and\n   ..\n   77          :type byte_range: tuple\n   78          :param range: A tuple of integer specifying the slice (in bytes)\n   79:             of the archive you want to receive\n   80  \n   81          :type validate_checksum: bool\n   ..\n  103      def download_to_file(self, filename, chunk_size=DefaultPartSize,\n  104                           verify_hashes=True, retry_exceptions=(socket.error,)):\n  105:         \"\"\"Download an archive to a file by name.\n  106  \n  107          :type filename: str\n  108:         :param filename: The name of the file where the archive\n  109              contents will be saved.\n  110  \n  111          :type chunk_size: int\n  112          :param chunk_size: The chunk size to use when downloading\n  113:             the archive.\n  114  \n  115          :type verify_hashes: bool\n  ...\n  126                              verify_hashes=True,\n  127                              retry_exceptions=(socket.error,)):\n  128:         \"\"\"Download an archive to a file object.\n  129  \n  130          :type output_file: file\n  131:         :param output_file: The file object where the archive\n  132              contents will be saved.\n  133  \n  134          :type chunk_size: int\n  135          :param chunk_size: The chunk size to use when downloading\n  136:             the archive.\n  137  \n  138          :type verify_hashes: bool\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/boto/glacier/layer1.py:\n  171          size of all the archives in the vault. The number of archives\n  172          and their total size are as of the last inventory generation.\n  173:         This means that if you add or remove an archive from a vault,\n  174          and then immediately use Describe Vault, the change in\n  175          contents will not be immediately reflected. If you want to\n  ...\n  244          you can use `Initiate a Job (POST jobs)`_ to initiate a new\n  245          inventory retrieval for a vault. The inventory contains the\n  246:         archive IDs you use to delete archives using `Delete Archive\n  247:         (DELETE archive)`_.\n  248  \n  249          This operation is idempotent.\n  ...\n  315  \n  316          + **ArchiveRetrievalCompleted** This event occurs when a job\n  317:           that was initiated for an archive retrieval is completed\n  318            (InitiateJob). The status of the completed job can be\n  319            \"Succeeded\" or \"Failed\". The notification sent to the SNS\n  ...\n  397          enables you to get a job output in the event you miss the job\n  398          completion notification or your first attempt to download it\n  399:         fails. For example, suppose you start an archive retrieval job\n  400:         to download an archive. After the job completes, you start to\n  401:         download the archive but encounter a network error. In this\n  402:         scenario, you can retry and download the archive while the job\n  403          exists.\n  404  \n  405  \n  406:         To retrieve an archive or retrieve a vault inventory from\n  407          Amazon Glacier, you first initiate a job, and after the job\n  408:         completes, you download the data. For an archive retrieval,\n  409:         the output is the archive data, and for an inventory\n  410          retrieval, it is the inventory list. The List Job operation\n  411          returns a list of these jobs sorted by job initiation time.\n  ...\n  517          \"\"\"\n  518          This operation initiates a job of the specified type. In this\n  519:         release, you can initiate a job to retrieve either an archive\n  520          or a vault inventory (a list of archives in a vault).\n  521  \n  ...\n  530          initiate a retrieval job, Amazon Glacier creates a job and\n  531          returns a job ID in the response. When Amazon Glacier\n  532:         completes the job, you can get the job output (archive or\n  533          inventory data). For information about getting job output, see\n  534          GetJobOutput operation.\n  ...\n  583          vault operation. However, in some scenarios, you might find\n  584          the vault inventory useful. For example, when you upload an\n  585:         archive, you can provide an archive description but not an\n  586:         archive name. Amazon Glacier provides you a unique archive ID,\n  587          an opaque string of characters. So, you might maintain your\n  588:         own database that maps archive names to their corresponding\n  589:         Amazon Glacier assigned archive IDs. You might find the vault\n  590          inventory useful in the event you need to reconcile\n  591          information in your database with the actual vault inventory.\n  592  \n  593:         **About Ranged Archive Retrieval**\n  594  \n  595:         You can initiate an archive retrieval for the whole archive or\n  596:         a range of the archive. In the case of ranged archive\n  597          retrieval, you specify a byte range to return or the whole\n  598:         archive. The range specified must be megabyte (MB) aligned,\n  599          that is the range start value must be divisible by 1 MB and\n  600          range end value plus 1 must be divisible by 1 MB or equal the\n  601:         end of the archive. If the ranged archive retrieval is not\n  602          megabyte aligned, this operation returns a 400 response.\n  603          Furthermore, to ensure you get checksum values for data you\n  ...\n  629              The dictionary can contain the following attributes:\n  630  \n  631:             * ArchiveId - The ID of the archive you want to retrieve.\n  632                This field is required only if the Type is set to\n  633:               archive-retrieval.\n  634              * Description - The optional description for the job.\n  635              * Format - When initiating a job to retrieve a vault\n  ...\n  640                output is ready for you to download.\n  641              * Type - The job type.  Valid values are:\n  642:               archive-retrieval|inventory-retrieval\n  643              * RetrievalByteRange - Optionally specify the range of\n  644                bytes to retrieve.\n  ...\n  664          using InitiateJob. Depending on the job type you specified\n  665          when you initiated the job, the output will be either the\n  666:         content of an archive or a vault inventory.\n  667  \n  668          A job ID will not expire for at least 24 hours after Amazon\n  ...\n  694             the Describe Job API, obtain job information of the job that\n  695             provided you the output. The response includes the checksum of\n  696:            the entire archive stored in Amazon Glacier. You compare this\n  697             value with the checksum you computed to ensure you have\n  698:            downloaded the entire archive content with no errors.\n  699  \n  700  \n  ...\n  707  \n  708          For conceptual information and the underlying REST API, go to\n  709:         `Downloading a Vault Inventory`_, `Downloading an Archive`_,\n  710          and `Get Job Output `_\n  711  \n  ...\n  743      # Archives\n  744  \n  745:     def upload_archive(self, vault_name, archive,\n  746                         linear_hash, tree_hash, description=None):\n  747          \"\"\"\n  748:         This operation adds an archive to a vault. This is a\n  749          synchronous operation, and for a successful upload, your data\n  750:         is durably persisted. Amazon Glacier returns the archive ID in\n  751:         the `x-amz-archive-id` header of the response.\n  752  \n  753:         You must use the archive ID to access your data in Amazon\n  754:         Glacier. After you upload an archive, you should save the\n  755:         archive ID returned so that you can retrieve or delete the\n  756:         archive later. Besides saving the archive ID, you can also\n  757          index it and give it a friendly name to allow for better\n  758:         searching. You can also use the optional archive description\n  759:         field to specify how the archive is referred to in an external\n  760          index of archives, such as you might create in Amazon\n  761          DynamoDB. You can also get the vault inventory to obtain a\n  762:         list of archive IDs in a vault. For more information, see\n  763          InitiateJob.\n  764  \n  ...\n  767          see `Computing Checksums`_.\n  768  \n  769:         You can optionally specify an archive description of up to\n  770:         1,024 printable ASCII characters. You can get the archive\n  771:         description when you either retrieve the archive or get the\n  772          vault inventory. For more information, see InitiateJob. Amazon\n  773          Glacier does not interpret the description in any way. An\n  774:         archive description does not need to be unique. You cannot use\n  775:         the description to retrieve or sort the archive list.\n  776  \n  777:         Archives are immutable. After you upload an archive, you\n  778:         cannot edit the archive or its description.\n  779  \n  780          An AWS account has full permission to perform all operations\n  ...\n  786  \n  787          For conceptual information and underlying REST API, go to\n  788:         `Uploading an Archive in Amazon Glacier`_ and `Upload\n  789:         Archive`_ in the Amazon Glacier Developer Guide .\n  790  \n  791          :type vault_name: str\n  792          :param vault_name: The name of the vault\n  793  \n  794:         :type archive: bytes\n  795:         :param archive: The data to upload.\n  796  \n  797          :type linear_hash: str\n  ...\n  805  \n  806          :type description: str\n  807:         :param description: The optional description of the archive you\n  808              are uploading.\n  809          \"\"\"\n  810:         response_headers = [('x-amz-archive-id', u'ArchiveId'),\n  811                              ('Location', u'Location'),\n  812                              ('x-amz-sha256-tree-hash', u'TreeHash')]\n  813          uri = 'vaults/%s/archives' % vault_name\n  814          try:\n  815:             content_length = str(len(archive))\n  816          except (TypeError, AttributeError):\n  817              # If a file like object is provided, try to retrieve\n  818              # the file size via fstat.\n  819:             content_length = str(os.fstat(archive.fileno()).st_size)\n  820          headers = {'x-amz-content-sha256': linear_hash,\n  821                     'x-amz-sha256-tree-hash': tree_hash,\n  822                     'Content-Length': content_length}\n  823          if description:\n  824:             headers['x-amz-archive-description'] = description\n  825:         if self._is_file_like(archive):\n  826:             sender = ResettingFileSender(archive)\n  827          else:\n  828              sender = None\n  829          return self.make_request('POST', uri, headers=headers,\n  830                                   sender=sender,\n  831:                                  data=archive, ok_responses=(201,),\n  832                                   response_headers=response_headers)\n  833  \n  834:     def _is_file_like(self, archive):\n  835:         return hasattr(archive, 'seek') and hasattr(archive, 'tell')\n  836  \n  837      def delete_archive(self, vault_name, archive_id):\n  838          \"\"\"\n  839:         This operation deletes an archive from a vault. Subsequent\n  840:         requests to initiate a retrieval of this archive will fail.\n  841:         Archive retrievals that are in progress for this archive ID\n  842          may or may not succeed according to the following scenarios:\n  843  \n  844  \n  845:         + If the archive retrieval job is actively preparing the data\n  846:           for download when Amazon Glacier receives the delete archive\n  847            request, the archival retrieval operation might fail.\n  848:         + If the archive retrieval job has successfully prepared the\n  849:           archive for download when Amazon Glacier receives the delete\n  850:           archive request, you will be able to download the output.\n  851  \n  852  \n  853          This operation is idempotent. Attempting to delete an already-\n  854:         deleted archive does not result in an error.\n  855  \n  856          An AWS account has full permission to perform all operations\n  ...\n  862  \n  863          For conceptual information and underlying REST API, go to\n  864:         `Deleting an Archive in Amazon Glacier`_ and `Delete Archive`_\n  865          in the Amazon Glacier Developer Guide .\n  866  \n  ...\n  869  \n  870          :type archive_id: string\n  871:         :param archive_id: The ID of the archive to delete.\n  872          \"\"\"\n  873          uri = 'vaults/%s/archives/%s' % (vault_name, archive_id)\n  ...\n  882          creates a multipart upload resource and returns its ID in the\n  883          response. The multipart upload ID is used in subsequent\n  884:         requests to upload parts of an archive (see\n  885          UploadMultipartPart).\n  886  \n  ...\n  900  \n  901  \n  902:         You don't need to know the size of the archive when you start\n  903          a multipart upload because Amazon Glacier does not require you\n  904:         to specify the overall archive size.\n  905  \n  906  \n  ...\n  932  \n  933          :type description: str\n  934:         :param description: The archive description that you are uploading in\n  935              parts.\n  936  \n  ...\n  943          headers = {'x-amz-part-size': str(part_size)}\n  944          if description:\n  945:             headers['x-amz-archive-description'] = description\n  946          uri = 'vaults/%s/multipart-uploads' % vault_name\n  947          response = self.make_request('POST', uri, headers=headers,\n  ...\n  954          \"\"\"\n  955          You call this operation to inform Amazon Glacier that all the\n  956:         archive parts have been uploaded and that Amazon Glacier can\n  957:         now assemble the archive from the uploaded parts. After\n  958:         assembling and saving the archive to the vault, Amazon Glacier\n  959:         returns the URI path of the newly created archive resource.\n  960:         Using the URI path, you can then access the archive. After you\n  961:         upload an archive, you should save the archive ID returned to\n  962:         retrieve the archive at a later point. You can also get the\n  963:         vault inventory to obtain a list of archive IDs in a vault.\n  964          For more information, see InitiateJob.\n  965  \n  966          In the request, you must include the computed SHA256 tree hash\n  967:         of the entire archive you have uploaded. For information about\n  968          computing a SHA256 tree hash, see `Computing Checksums`_. On\n  969          the server side, Amazon Glacier also constructs the SHA256\n  970:         tree hash of the assembled archive. If the values match,\n  971:         Amazon Glacier saves the archive to the vault; otherwise, it\n  972          returns an error, and the operation fails. The ListParts\n  973          operation returns a list of parts uploaded for a specific\n  ...\n  976  \n  977          Additionally, Amazon Glacier also checks for any missing\n  978:         content ranges when assembling the archive, if missing content\n  979          ranges are found, Amazon Glacier returns an error and the\n  980          operation fails.\n  ...\n  983          your first successful complete multipart upload, if you call\n  984          the operation again within a short period, the operation will\n  985:         succeed and return the same archive ID. This is useful in the\n  986          event you experience a network issue that causes an aborted\n  987          connection or receive a 500 server error, in which case you\n  988          can repeat your Complete Multipart Upload request and get the\n  989:         same archive ID without creating duplicate archives. Note,\n  990          however, that after the multipart upload completes, you cannot\n  991          call the List Parts operation and the multipart upload will\n  ...\n 1006  \n 1007          :type checksum: string\n 1008:         :param checksum: The SHA256 tree hash of the entire archive. It is the\n 1009              tree hash of SHA256 tree hash of the individual parts. If the value\n 1010              you specify in the request does not match the SHA256 tree hash of\n 1011:             the final assembled archive as computed by Amazon Glacier, Amazon\n 1012              Glacier returns an error and the request fails.\n 1013  \n ....\n 1019  \n 1020          :type sha256_treehash: str\n 1021:         :param sha256_treehash: The SHA256 tree hash of the entire archive.\n 1022              It is the tree hash of SHA256 tree hash of the individual parts.\n 1023              If the value you specify in the request does not match the SHA256\n 1024:             tree hash of the final assembled archive as computed by Amazon\n 1025              Glacier, Amazon Glacier returns an error and the request fails.\n 1026  \n 1027          :type archive_size: int\n 1028          :param archive_size: The total size, in bytes, of the entire\n 1029:             archive. This value should be the sum of all the sizes of\n 1030              the individual parts that you uploaded.\n 1031          \"\"\"\n 1032:         response_headers = [('x-amz-archive-id', u'ArchiveId'),\n 1033                              ('Location', u'Location')]\n 1034          headers = {'x-amz-sha256-tree-hash': sha256_treehash,\n 1035:                    'x-amz-archive-size': str(archive_size)}\n 1036          uri = 'vaults/%s/multipart-uploads/%s' % (vault_name, upload_id)\n 1037          response = self.make_request('POST', uri, headers=headers,\n ....\n 1137      def list_parts(self, vault_name, upload_id, limit=None, marker=None):\n 1138          \"\"\"\n 1139:         This operation lists the parts of an archive that have been\n 1140          uploaded in a specific multipart upload. You can make this\n 1141          request at any time during an in-progress multipart upload\n ....\n 1194                      tree_hash, byte_range, part_data):\n 1195          \"\"\"\n 1196:         This operation uploads a part of an archive. You can upload\n 1197:         archive parts in any order. You can also upload them in\n 1198          parallel. You can upload up to 10,000 parts for a multipart\n 1199          upload.\n ....\n 1262          :type byte_range: tuple of ints\n 1263          :param byte_range: Identifies the range of bytes in the assembled\n 1264:             archive that will be uploaded in this part. Amazon Glacier uses\n 1265:             this information to assemble the archive in the proper sequence.\n 1266              The format of this header follows RFC 2616. An example header is\n 1267              Content-Range:bytes 0-4194303/*.\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/boto/glacier/utils.py:\n   36  \n   37      Glacier allows a maximum of 10,000 parts per upload.  It also\n   38:     states that the maximum archive size is 10,000 * 4 GB, which means\n   39      the part size can range from 1MB to 4GB (provided it is one 1MB\n   40      multiplied by a power of 2).\n   ..\n   48      ``size_in_bytes`` will be returned.\n   49  \n   50:     If the file size is greater than the maximum allowed archive\n   51      size of 10,000 * 4GB, a ``ValueError`` will be raised.\n   52  \n   53      \"\"\"\n   54      # The default part size (4 MB) will be too small for a very large\n   55:     # archive, as there is a limit of 10,000 parts in a multipart upload.\n   56:     # This puts the maximum allowed archive size with the default part size\n   57      # at 40,000 MB. We need to do a sanity check on the part size, and find\n   58      # one that works if the default is too small.\n   ..\n  164  \n  165  class ResettingFileSender(object):\n  166:     def __init__(self, archive):\n  167:         self._archive = archive\n  168:         self._starting_offset = archive.tell()\n  169  \n  170      def __call__(self, connection, method, path, body, headers):\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/boto/glacier/vault.py:\n   72      def upload_archive(self, filename, description=None):\n   73          \"\"\"\n   74:         Adds an archive to a vault. For archives greater than 100MB the\n   75          multipart upload will be used.\n   76  \n   ..\n   79  \n   80          :type description: str\n   81:         :param description: An optional description for the archive.\n   82  \n   83          :rtype: str\n   84:         :return: The archive id of the newly created archive\n   85          \"\"\"\n   86          if os.path.getsize(filename) > self.SingleOperationThreshold:\n   ..\n   90      def _upload_archive_single_operation(self, filename, description):\n   91          \"\"\"\n   92:         Adds an archive to a vault in a single operation. It's recommended for\n   93          archives less than 100MB\n   94  \n   ..\n   97  \n   98          :type description: str\n   99:         :param description: A description for the archive.\n  100  \n  101          :rtype: str\n  102:         :return: The archive id of the newly created archive\n  103          \"\"\"\n  104          with open(filename, 'rb') as fileobj:\n  ...\n  113                                description=None):\n  114          \"\"\"\n  115:         Create a new archive and begin a multi-part upload to it.\n  116:         Returns a file-like object to which the data for the archive\n  117          can be written. Once all the data is written the file-like\n  118          object should be closed, you can then call the get_archive_id\n  119:         method on it to get the ID of the created archive.\n  120  \n  121          :type part_size: int\n  ...\n  123  \n  124          :type description: str\n  125:         :param description: An optional description for the archive.\n  126  \n  127          :rtype: :class:`boto.glacier.writer.Writer`\n  128:         :return: A Writer object that to which the archive data\n  129              should be written.\n  130          \"\"\"\n  ...\n  137                                   description=None, upload_id_callback=None):\n  138          \"\"\"\n  139:         Create a new archive and upload the data from the given file\n  140          or file-like object.\n  141  \n  ...\n  147  \n  148          :type description: str\n  149:         :param description: An optional description for the archive.\n  150  \n  151          :type upload_id_callback: function\n  ...\n  155  \n  156          :rtype: str\n  157:         :return: The archive id of the newly created archive\n  158          \"\"\"\n  159          part_size = self.DefaultPartSize\n  ...\n  164              except ValueError:\n  165                  raise UploadArchiveError(\"File size of %s bytes exceeds \"\n  166:                                          \"40,000 GB archive limit of Glacier.\")\n  167              file_obj = open(filename, \"rb\")\n  168          writer = self.create_archive_writer(\n  ...\n  217  \n  218          :rtype: str\n  219:         :return: The archive id of the newly created archive\n  220  \n  221          \"\"\"\n  ...\n  239                                              **kwargs):\n  240          \"\"\"\n  241:         Create a new archive from a file and upload the given\n  242          file.\n  243  \n  ...\n  260  \n  261          :rtype: str\n  262:         :return: The archive id of the newly created archive\n  263  \n  264          \"\"\"\n  ...\n  270                           description=None):\n  271          \"\"\"\n  272:         Initiate a archive retrieval job to download the data from an\n  273:         archive. You will need to wait for the notification from\n  274          Amazon (via SNS) before you can actually download the data,\n  275          this takes around 4 hours.\n  276  \n  277          :type archive_id: str\n  278:         :param archive_id: The id of the archive\n  279  \n  280          :type description: str\n  ...\n  289          :return: A Job object representing the retrieval job.\n  290          \"\"\"\n  291:         job_data = {'Type': 'archive-retrieval',\n  292                      'ArchiveId': archive_id}\n  293          if sns_topic is not None:\n  ...\n  387      def delete_archive(self, archive_id):\n  388          \"\"\"\n  389:         This operation deletes an archive from the vault.\n  390  \n  391          :type archive_id: str\n  392:         :param archive_id: The ID for the archive to be deleted.\n  393          \"\"\"\n  394          return self.layer1.delete_archive(self.name, archive_id)\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/boto/glacier/writer.py:\n  206      \"\"\"\n  207      Presents a file-like object for writing to a Amazon Glacier\n  208:     Archive. The data is written using the multi-part upload API.\n  209      \"\"\"\n  210      def __init__(self, vault, upload_id, part_size, chunk_size=_ONE_MEGABYTE):\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/boto/manage/volume.py:\n  414          super(Volume, self).delete()\n  415  \n  416:     def archive(self):\n  417          # snapshot volume, trim snaps, delete volume-id\n  418          pass\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/boto/s3/key.py:\n 1899  \n 1900      def restore(self, days, headers=None):\n 1901:         \"\"\"Restore an object from an archive.\n 1902  \n 1903          :type days: int\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/bs4/builder/__init__.py:\n  251          \"td\" : [\"headers\"],\n  252          \"form\" : [\"accept-charset\"],\n  253:         \"object\" : [\"archive\"],\n  254  \n  255          # These are HTML5 specific, as are *.accesskey and *.dropzone above.\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/django/contrib/gis/db/backends/spatialite/operations.py:\n    1  \"\"\"\n    2  SQL functions reference lists:\n    3: https://web.archive.org/web/20130407175746/https://www.gaia-gis.it/gaia-sins/spatialite-sql-4.0.0.html\n    4  https://www.gaia-gis.it/gaia-sins/spatialite-sql-4.2.1.html\n    5  \"\"\"\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/django/core/management/templates.py:\n   17  from django.core.management.utils import handle_extensions\n   18  from django.template import Context, Engine\n   19: from django.utils import archive, six\n   20  from django.utils.six.moves.urllib.request import urlretrieve\n   21  from django.utils.version import get_docs_version\n   ..\n  282  \n  283          # Move the temporary file to a filename that has better\n  284:         # chances of being recognized by the archive utils\n  285          if used_name != guessed_filename:\n  286              guessed_path = path.join(tempdir, guessed_filename)\n  ...\n  312              self.stdout.write(\"Extracting %s\\n\" % filename)\n  313          try:\n  314:             archive.extract(filename, tempdir)\n  315              return tempdir\n  316:         except (archive.ArchiveException, IOError) as e:\n  317              raise CommandError(\"couldn't extract file %s to %s: %s\" %\n  318                                 (filename, tempdir, e))\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/django/template/defaulttags.py:\n 1004         list of days, only displaying the month if it changes::\n 1005  \n 1006:             <h1>Archive for {{ year }}</h1>\n 1007  \n 1008              {% for date in days %}\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/django/utils/archive.py:\n    1  \"\"\"\n    2: Based on \"python-archive\" -- http://pypi.python.org/pypi/python-archive/\n    3  \n    4  Copyright (c) 2010 Gary Wilson Jr. <gary.wilson@gmail.com> and contributors.\n    .\n   33  class ArchiveException(Exception):\n   34      \"\"\"\n   35:     Base exception class for all archive errors.\n   36      \"\"\"\n   37  \n   ..\n   39  class UnrecognizedArchiveFormat(ArchiveException):\n   40      \"\"\"\n   41:     Error raised when passed file is not a recognized archive format.\n   42      \"\"\"\n   43  \n   ..\n   48      specified by to_path.\n   49      \"\"\"\n   50:     with Archive(path) as archive:\n   51:         archive.extract(to_path)\n   52  \n   53  \n   54: class Archive(object):\n   55      \"\"\"\n   56:     The external API class that encapsulates an archive implementation.\n   57      \"\"\"\n   58      def __init__(self, file):\n   ..\n   69              except AttributeError:\n   70                  raise UnrecognizedArchiveFormat(\n   71:                     \"File object not a recognized archive format.\")\n   72          base, tail_ext = os.path.splitext(filename.lower())\n   73          cls = extension_map.get(tail_ext)\n   ..\n   77          if not cls:\n   78              raise UnrecognizedArchiveFormat(\n   79:                 \"Path not a recognized archive format: %s\" % filename)\n   80          return cls\n   81  \n   ..\n   98  class BaseArchive(object):\n   99      \"\"\"\n  100:     Base Archive class.  Implementations should inherit this class.\n  101      \"\"\"\n  102      @staticmethod\n  103      def _copy_permissions(mode, filename):\n  104          \"\"\"\n  105:         If the file in the archive has some permissions (this assumes a file\n  106          won't be writable/executable without being readable), apply those\n  107          permissions to the unarchived file.\n  ...\n  123          \"\"\"\n  124          Returns true if all the paths have the same leading path name\n  125:         (i.e., everything is in one subdirectory in an archive)\n  126          \"\"\"\n  127          common_prefix = None\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/django/utils/feedgenerator.py:\n   20  \n   21  For definitions of the different versions of RSS, see:\n   22: http://web.archive.org/web/20110718035220/http://diveintomark.org/archives/2004/02/04/incompatible-rss\n   23  \"\"\"\n   24  from __future__ import unicode_literals\n   ..\n   79      Creates a TagURI.\n   80  \n   81:     See http://web.archive.org/web/20110514113830/http://diveintomark.org/archives/2004/05/28/howto-atom-id\n   82      \"\"\"\n   83      bits = urlparse(url)\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/django/utils/timesince.py:\n   30  \n   31      Adapted from\n   32:     http://web.archive.org/web/20060617175230/http://blog.natbat.co.uk/archive/2003/Jun/14/time_since\n   33      \"\"\"\n   34      # Convert datetime.date to datetime.datetime for comparison.\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/django/views/generic/dates.py:\n  433  class ArchiveIndexView(MultipleObjectTemplateResponseMixin, BaseArchiveIndexView):\n  434      \"\"\"\n  435:     Top-level archive of date-based items.\n  436      \"\"\"\n  437      template_name_suffix = '_archive'\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/docutils/utils/urischemes.py:\n   62        'iris.beep': 'iris.beep; RFC 3983',\n   63        'iseek' : 'See www.ambrosiasw.com;  a little util for OS X.',\n   64:       'jar': 'Java archive',\n   65        'javascript': ('JavaScript code; evaluates the expression after the '\n   66                       'colon'),\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/faker/providers/address/en_GB/__init__.py:\n  105      def postcode(cls):\n  106          \"\"\"\n  107:         See http://web.archive.org/web/20090930140939/http://www.govtalk.gov.uk/gdsc/html/noframes/PostCode-2-1-Release.htm\n  108          \"\"\"\n  109          postcode = ''\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/faker/providers/company/en_US/__init__.py:\n   47          (\n   48              'ability', 'access', 'adapter', 'algorithm', 'alliance', 'analyzer', 'application', 'approach',\n   49:             'architecture', 'archive', 'artificial intelligence', 'array', 'attitude', 'benchmark',\n   50              'budgetary management', 'capability', 'capacity', 'challenge', 'circuit', 'collaboration', 'complexity',\n   51              'concept', 'conglomeration', 'contingency', 'core', 'customer loyalty', 'database', 'data-warehouse',\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/faker/providers/file/__init__.py:\n   35          \"application/xml-dtd\", # DTD files; Defined by RFC 3023\n   36          \"application/xop+xml\", # XOP\n   37:         \"application/zip\", # ZIP archive files; Registered[8]\n   38          \"application/gzip\",         # Gzip, Defined in RFC 6713\n   39      )\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/gevent/subprocess.py:\n  825                      # use the w9xpopen intermediate program. For more\n  826                      # information, see KB Q150956\n  827:                     # (http://web.archive.org/web/20011105084002/http://support.microsoft.com/support/kb/articles/Q150/9/56.asp)\n  828                      w9xpopen = self._find_w9xpopen()\n  829                      args = '\"%s\" %s' % (w9xpopen, args)\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/jedi/_compatibility.py:\n   78                  # At least zipimporter does not have path attribute\n   79                  module_path = os.path.dirname(loader.get_filename(string))\n   80:             if hasattr(loader, 'archive'):\n   81                  module_file = DummyFile(loader, string)\n   82              else:\n   ..\n   97              is_package = False\n   98  \n   99:     if hasattr(loader, 'archive'):\n  100:         module_path = loader.archive\n  101  \n  102      return module_file, module_path, is_package\n  ...\n  120                  if loader:\n  121                      is_package = loader.is_package(string)\n  122:                     is_archive = hasattr(loader, 'archive')\n  123                      try:\n  124                          module_path = loader.get_filename(string)\n  ...\n  132                          module_path = os.path.dirname(module_path)\n  133                      if is_archive:\n  134:                         module_path = loader.archive\n  135                      file = None\n  136                      if not is_package or is_archive:\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/jinja2/environment.py:\n  697              zip_file = ZipFile(target, 'w', dict(deflated=ZIP_DEFLATED,\n  698                                                   stored=ZIP_STORED)[zip])\n  699:             log_function('Compiling into Zip archive \"%s\"' % target)\n  700          else:\n  701              if not os.path.isdir(target):\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/_vendor/distlib/_backport/shutil.py:\n   53  \n   54  class ReadError(EnvironmentError):\n   55:     \"\"\"Raised when an archive cannot be read\"\"\"\n   56  \n   57  class RegistryError(Exception):\n   ..\n  379  \n  380      'owner' and 'group' can be used to define an owner and a group for the\n  381:     archive that is being built. If not provided, the current owner and group\n  382      will be used.\n  383  \n  ...\n  410      # creating the tarball\n  411      if logger is not None:\n  412:         logger.info('Creating tar archive')\n  413  \n  414      uid = _get_uid(owner)\n  ...\n  519  \n  520  def register_archive_format(name, function, extra_args=None, description=''):\n  521:     \"\"\"Registers an archive format.\n  522  \n  523      name is the name of the format. function is the callable that will be\n  ...\n  544  def make_archive(base_name, format, root_dir=None, base_dir=None, verbose=0,\n  545                   dry_run=0, owner=None, group=None, logger=None):\n  546:     \"\"\"Create an archive file (eg. zip or tar).\n  547  \n  548      'base_name' is the name of the file to create, minus any format-specific\n  549:     extension; 'format' is the archive format: one of \"zip\", \"tar\", \"bztar\"\n  550      or \"gztar\".\n  551  \n  552      'root_dir' is a directory that will be the root directory of the\n  553:     archive; ie. we typically chdir into 'root_dir' before creating the\n  554:     archive.  'base_dir' is the directory where we start archiving from;\n  555      ie. 'base_dir' will be the common prefix of all files and\n  556:     directories in the archive.  'root_dir' and 'base_dir' both default\n  557:     to the current directory.  Returns the name of the archive file.\n  558  \n  559:     'owner' and 'group' are used when creating a tar archive. By default,\n  560      uses the current owner and group.\n  561      \"\"\"\n  ...\n  576          format_info = _ARCHIVE_FORMATS[format]\n  577      except KeyError:\n  578:         raise ValueError(\"unknown archive format '%s'\" % format)\n  579  \n  580      func = format_info[0]\n  ...\n  635      `function` is the callable that will be\n  636      used to unpack archives. The callable will receive archives to unpack.\n  637:     If it's unable to handle an archive, it needs to raise a ReadError\n  638      exception.\n  639  \n  ...\n  664          import zipfile\n  665      except ImportError:\n  666:         raise ReadError('zlib not supported, cannot unpack this archive.')\n  667  \n  668      if not zipfile.is_zipfile(filename):\n  ...\n  726  \n  727  def unpack_archive(filename, extract_dir=None, format=None):\n  728:     \"\"\"Unpack an archive.\n  729  \n  730:     `filename` is the name of the archive.\n  731  \n  732:     `extract_dir` is the name of the target directory, where the archive\n  733      is unpacked. If not provided, the current working directory is used.\n  734  \n  735:     `format` is the archive format: one of \"zip\", \"tar\", or \"gztar\". Or any\n  736      other registered format. If not provided, unpack_archive will use the\n  737      filename extension and see if an unpacker was registered for that\n  ...\n  755          format = _find_unpack_format(filename)\n  756          if format is None:\n  757:             raise ReadError(\"Unknown archive format '{0}'\".format(filename))\n  758  \n  759          func = _UNPACK_FORMATS[format][1]\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/_vendor/distlib/_backport/tarfile.py:\n  781  \n  782  class ExFileObject(object):\n  783:     \"\"\"File-like object for reading an archive member.\n  784         Is returned by TarFile.extractfile().\n  785      \"\"\"\n  ...\n  923  class TarInfo(object):\n  924      \"\"\"Informational class which holds the details about an\n  925:        archive member given by a tar header block.\n  926         TarInfo objects are returned by TarFile.getmember(),\n  927         TarFile.getmembers() and TarFile.gettarinfo() and are\n  ...\n 1594                                  # are passed to the caller as exceptions.\n 1595  \n 1596:     format = DEFAULT_FORMAT     # The format to use when creating an archive.\n 1597  \n 1598      encoding = ENCODING         # Encoding for 8-bit character strings.\n ....\n 1607              tarinfo=None, dereference=None, ignore_zeros=None, encoding=None,\n 1608              errors=\"surrogateescape\", pax_headers=None, debug=None, errorlevel=None):\n 1609:         \"\"\"Open an (uncompressed) tar archive `name'. `mode' is either 'r' to\n 1610:            read from an existing archive, 'a' to append data to an existing\n 1611             file or 'w' to create a new file overwriting an existing one. `mode'\n 1612             defaults to 'r'.\n ....\n 1664          self._loaded = False    # flag if all members have been read\n 1665          self.offset = self.fileobj.tell()\n 1666:                                 # current position in the archive file\n 1667          self.inodes = {}        # dictionary caching the inodes of\n 1668:                                 # archive members already added\n 1669  \n 1670          try:\n ....\n 1674  \n 1675              if self.mode == \"a\":\n 1676:                 # Move to the end of the archive,\n 1677                  # before the first empty block.\n 1678                  while True:\n ....\n 1713      @classmethod\n 1714      def open(cls, name=None, mode=\"r\", fileobj=None, bufsize=RECORDSIZE, **kwargs):\n 1715:         \"\"\"Open a tar archive for reading, writing or appending. Return\n 1716             an appropriate TarFile class.\n 1717  \n ....\n 1789      @classmethod\n 1790      def taropen(cls, name, mode=\"r\", fileobj=None, **kwargs):\n 1791:         \"\"\"Open uncompressed tar archive name for reading or writing.\n 1792          \"\"\"\n 1793          if len(mode) > 1 or mode not in \"raw\":\n ....\n 1797      @classmethod\n 1798      def gzopen(cls, name, mode=\"r\", fileobj=None, compresslevel=9, **kwargs):\n 1799:         \"\"\"Open gzip compressed tar archive name for reading or writing.\n 1800             Appending is not allowed.\n 1801          \"\"\"\n ....\n 1828      @classmethod\n 1829      def bz2open(cls, name, mode=\"r\", fileobj=None, compresslevel=9, **kwargs):\n 1830:         \"\"\"Open bzip2 compressed tar archive name for reading or writing.\n 1831             Appending is not allowed.\n 1832          \"\"\"\n ....\n 1864      def close(self):\n 1865          \"\"\"Close the TarFile. In write-mode, two finishing zero blocks are\n 1866:            appended to the archive.\n 1867          \"\"\"\n 1868          if self.closed:\n ....\n 1884      def getmember(self, name):\n 1885          \"\"\"Return a TarInfo object for member `name'. If `name' can not be\n 1886:            found in the archive, KeyError is raised. If a member occurs more\n 1887:            than once in the archive, its last occurrence is assumed to be the\n 1888             most up-to-date version.\n 1889          \"\"\"\n ....\n 1894  \n 1895      def getmembers(self):\n 1896:         \"\"\"Return the members of the archive as a list of TarInfo objects. The\n 1897:            list has the same order as the members in the archive.\n 1898          \"\"\"\n 1899          self._check()\n 1900          if not self._loaded:    # if we want to obtain a list of\n 1901              self._load()        # all members, we first have to\n 1902:                                 # scan the whole archive.\n 1903          return self.members\n 1904  \n 1905      def getnames(self):\n 1906:         \"\"\"Return the members of the archive as a list of their names. It has\n 1907             the same order as the list returned by getmembers().\n 1908          \"\"\"\n ....\n 1914             modify some of the TarInfo's attributes before you add it using\n 1915             addfile(). If given, `arcname' specifies an alternative name for the\n 1916:            file in the archive.\n 1917          \"\"\"\n 1918          self._check(\"aw\")\n ....\n 1923              name = fileobj.name\n 1924  \n 1925:         # Building the name of the member in the archive.\n 1926          # Backward slashes are converted to forward slashes,\n 1927          # Absolute paths are turned to relative paths.\n ....\n 2037  \n 2038      def add(self, name, arcname=None, recursive=True, exclude=None, filter=None):\n 2039:         \"\"\"Add the file `name' to the archive. `name' may be any type of file\n 2040             (directory, fifo, symbolic link, etc.). If given, `arcname'\n 2041:            specifies an alternative name for the file in the archive.\n 2042             Directories are added recursively by default. This can be avoided by\n 2043             setting `recursive' to False. `exclude' is a function that should\n ....\n 2045             that expects a TarInfo object argument and returns the changed\n 2046             TarInfo object, if it returns None the TarInfo object will be\n 2047:            excluded from the archive.\n 2048          \"\"\"\n 2049          self._check(\"aw\")\n ....\n 2061                  return\n 2062  \n 2063:         # Skip if somebody tries to archive the archive...\n 2064          if self.name is not None and os.path.abspath(name) == self.name:\n 2065              self._dbg(2, \"tarfile: Skipped %r\" % name)\n ....\n 2082                  return\n 2083  \n 2084:         # Append the tar header and data to the archive.\n 2085          if tarinfo.isreg():\n 2086              f = bltn_open(name, \"rb\")\n ....\n 2099  \n 2100      def addfile(self, tarinfo, fileobj=None):\n 2101:         \"\"\"Add the TarInfo object `tarinfo' to the archive. If `fileobj' is\n 2102:            given, tarinfo.size bytes are read from it and added to the archive.\n 2103             You can create TarInfo objects using gettarinfo().\n 2104             On Windows platforms, `fileobj' should always be opened with mode\n ....\n 2125  \n 2126      def extractall(self, path=\".\", members=None):\n 2127:         \"\"\"Extract all members from the archive to the current working\n 2128             directory and set owner, modification time and permissions on\n 2129             directories afterwards. `path' specifies a different directory\n ....\n 2163  \n 2164      def extract(self, member, path=\"\", set_attrs=True):\n 2165:         \"\"\"Extract a member from the archive to the current working directory,\n 2166             using its full name. Its file information is extracted as accurately\n 2167             as possible. `member' may be a filename or a TarInfo object. You can\n ....\n 2198  \n 2199      def extractfile(self, member):\n 2200:         \"\"\"Extract a member from the archive as a file object. `member' may be\n 2201             a filename or a TarInfo object. If `member' is a regular file, a\n 2202             file-like object is returned. If `member' is a link, a file-like\n ....\n 2248          upperdirs = os.path.dirname(targetpath)\n 2249          if upperdirs and not os.path.exists(upperdirs):\n 2250:             # Create directories that are not part of the archive with\n 2251              # default permissions.\n 2252              os.makedirs(upperdirs)\n ....\n 2368                                       targetpath)\n 2369              except KeyError:\n 2370:                 raise ExtractError(\"unable to resolve link inside archive\")\n 2371  \n 2372      def chown(self, tarinfo, targetpath):\n ....\n 2413      #--------------------------------------------------------------------------\n 2414      def next(self):\n 2415:         \"\"\"Return the next member of the archive as a TarInfo object, when\n 2416             TarFile is opened for reading. Return None if there is no more\n 2417             available.\n ....\n 2462  \n 2463      def _getmember(self, name, tarinfo=None, normalize=False):\n 2464:         \"\"\"Find an archive member by name from bottom to top.\n 2465             If tarinfo is given, it is used as the starting point.\n 2466          \"\"\"\n ....\n 2485  \n 2486      def _load(self):\n 2487:         \"\"\"Read through the entire archive file and look for readable\n 2488             members.\n 2489          \"\"\"\n ....\n 2505      def _find_link_target(self, tarinfo):\n 2506          \"\"\"Find the target member of a symlink or hardlink member in the\n 2507:            archive.\n 2508          \"\"\"\n 2509          if tarinfo.issym():\n 2510:             # Always search the entire archive.\n 2511              linkname = os.path.dirname(tarinfo.name) + \"/\" + tarinfo.linkname\n 2512              limit = None\n 2513          else:\n 2514:             # Search the archive before the link, because a hard link is\n 2515              # just a reference to an already archived file.\n 2516              linkname = tarinfo.linkname\n ....\n 2545          else:\n 2546              # An exception occurred. We must not call close() because\n 2547:             # it would try to write end-of-archive blocks and padding.\n 2548              if not self._extfileobj:\n 2549                  self.fileobj.close()\n ....\n 2594  #--------------------\n 2595  def is_tarfile(name):\n 2596:     \"\"\"Return True if name points to a tar archive that we\n 2597         are able to handle, else return False.\n 2598      \"\"\"\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/_vendor/distlib/database.py:\n  345      def source_url(self):\n  346          \"\"\"\n  347:         The source archive download URL for this distribution.\n  348          \"\"\"\n  349          return self.metadata.source_url\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/_vendor/distlib/locators.py:\n  205          The current implementation favours https:// URLs over http://, archives\n  206          from PyPI over those from other locations, wheel compatibility (if a\n  207:         wheel) and then the archive name.\n  208          \"\"\"\n  209          result = url2\n  ...\n  315          Update a result dictionary (the final result from _get_project) with a\n  316          dictionary for a specific version, which typically holds information\n  317:         gleaned from a filename or URL for an archive for the distribution.\n  318          \"\"\"\n  319          name = info.pop('name')\n  ...\n  839          \"\"\"\n  840          Should a filename be considered as a candidate for a distribution\n  841:         archive? As well as the filename, the directory which contains it\n  842          is provided, though not used by the current implementation.\n  843          \"\"\"\n  ...\n  883      This locator uses special extended metadata (not available on PyPI) and is\n  884      the basis of performant dependency resolution in distlib. Other locators\n  885:     require archive downloads before dependencies can be determined! As you\n  886      might imagine, that can be slow.\n  887      \"\"\"\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/_vendor/distlib/resources.py:\n  213      def __init__(self, module):\n  214          super(ZipResourceFinder, self).__init__(module)\n  215:         archive = self.loader.archive\n  216:         self.prefix_len = 1 + len(archive)\n  217          # PyPy doesn't have a _files attr on zipimporter, and you can't set one\n  218          if hasattr(self.loader, '_files'):\n  219              self._files = self.loader._files\n  220          else:\n  221:             self._files = zipimport._zip_directory_cache[archive]\n  222          self.index = sorted(self._files)\n  223  \n  ...\n  244  \n  245      def get_cache_info(self, resource):\n  246:         prefix = self.loader.archive\n  247          path = resource.path[1 + len(prefix):]\n  248          return prefix, path\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/_vendor/distlib/util.py:\n 1062      dest_dir = os.path.abspath(dest_dir)\n 1063      plen = len(dest_dir)\n 1064:     archive = None\n 1065      if format is None:\n 1066          if archive_filename.endswith(('.zip', '.whl')):\n ....\n 1079      try:\n 1080          if format == 'zip':\n 1081:             archive = ZipFile(archive_filename, 'r')\n 1082              if check:\n 1083:                 names = archive.namelist()\n 1084                  for name in names:\n 1085                      check_path(name)\n 1086          else:\n 1087:             archive = tarfile.open(archive_filename, mode)\n 1088              if check:\n 1089:                 names = archive.getnames()\n 1090                  for name in names:\n 1091                      check_path(name)\n ....\n 1095              # contains non-ASCII characters - it leads to an implicit\n 1096              # bytes -> unicode conversion using ASCII to decode.\n 1097:             for tarinfo in archive.getmembers():\n 1098                  if not isinstance(tarinfo.name, text_type):\n 1099                      tarinfo.name = tarinfo.name.decode('utf-8')\n 1100:         archive.extractall(dest_dir)\n 1101  \n 1102      finally:\n 1103:         if archive:\n 1104:             archive.close()\n 1105  \n 1106  \n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/_vendor/distlib/wheel.py:\n  421  \n  422          # Now, at last, RECORD.\n  423:         # Paths in here are archive paths - nothing else makes sense.\n  424          self.write_records((distinfo, info_dir), libdir, archive_paths)\n  425          # Now, ready to build the zip file\n  ...\n  802          Update the contents of a wheel in a generic way. The modifier should\n  803          be a callable which expects a dictionary argument: its keys are\n  804:         archive-entry paths, and its values are absolute filesystem paths\n  805:         where the contents the corresponding archive entries can be found. The\n  806          modifier is free to change the contents of the files pointed to, add\n  807          new entries and remove entries, before returning. This method will\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/_vendor/pkg_resources/__init__.py:\n 1546      def _setup_prefix(self):\n 1547          # we assume here that our metadata may be nested inside a \"basket\"\n 1548:         # of multiple eggs; that's why we use module_path instead of .archive\n 1549          path = self.module_path\n 1550          old = None\n ....\n 1678      def __init__(self, module):\n 1679          EggProvider.__init__(self, module)\n 1680:         self.zip_pre = self.loader.archive + os.sep\n 1681  \n 1682      def _zipinfo_name(self, fspath):\n 1683          # Convert a virtual filename (full path to file) into a zipfile subpath\n 1684:         # usable with the zipimport directory cache for our target archive\n 1685          if fspath.startswith(self.zip_pre):\n 1686              return fspath[len(self.zip_pre):]\n ....\n 1701      @property\n 1702      def zipinfo(self):\n 1703:         return self._zip_manifests.load(self.loader.archive)\n 1704  \n 1705      def get_resource_filename(self, manager, resource_name):\n ....\n 1909          \"\"\"Create a metadata provider from a zipimporter\"\"\"\n 1910  \n 1911:         self.zip_pre = importer.archive + os.sep\n 1912          self.loader = importer\n 1913          if importer.prefix:\n 1914:             self.module_path = os.path.join(importer.archive, importer.prefix)\n 1915          else:\n 1916:             self.module_path = importer.archive\n 1917          self._setup_prefix()\n 1918  \n ....\n 1942      Find eggs in zip files; possibly multiple nested eggs.\n 1943      \"\"\"\n 1944:     if importer.archive.endswith('.whl'):\n 1945          # wheels are not supported with this finder\n 1946          # they don't have PKG-INFO metadata, and won't ever contain eggs\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/cmdoptions.py:\n  566      callback=_merge_hash,\n  567      type='string',\n  568:     help=\"Verify that the package's archive matches this \"\n  569           'hash before installing. Example: --hash=sha256:abcdef...')\n  570  \n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/commands/download.py:\n   36        %prog [options] [-e] <vcs project url> ...\n   37        %prog [options] [-e] <local project path> ...\n   38:       %prog [options] <archive url/path> ...\"\"\"\n   39  \n   40      summary = 'Download packages.'\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/commands/hash.py:\n   16  class HashCommand(Command):\n   17      \"\"\"\n   18:     Compute a hash of a local package archive.\n   19  \n   20      These can be used with --hash in a requirements file to do repeatable\n   ..\n   51  def _hash_of_file(path, algorithm):\n   52      \"\"\"Return the hash digest of a file.\"\"\"\n   53:     with open(path, 'rb') as archive:\n   54          hash = hashlib.new(algorithm)\n   55:         for chunk in read_chunks(archive):\n   56              hash.update(chunk)\n   57      return hash.hexdigest()\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/commands/install.py:\n   48        %prog [options] [-e] <vcs project url> ...\n   49        %prog [options] [-e] <local project path> ...\n   50:       %prog [options] <archive url/path> ...\"\"\"\n   51  \n   52      summary = 'Install packages.'\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/commands/wheel.py:\n   40        %prog [options] [-e] <vcs project url> ...\n   41        %prog [options] [-e] <local project path> ...\n   42:       %prog [options] <archive url/path> ...\"\"\"\n   43  \n   44      summary = 'Build wheels from your requirements.'\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/download.py:\n  468  \n  469  def is_archive_file(name):\n  470:     \"\"\"Return True if `name` is a considered as an archive file.\"\"\"\n  471      ext = splitext(name)[1].lower()\n  472      if ext in ARCHIVE_EXTENSIONS:\n  ...\n  659                                                       hashes)\n  660  \n  661:     # unpack the archive to the build dir location. even when only downloading\n  662      # archives, they have to be unpacked to parse dependencies\n  663      unpack_file(from_path, location, content_type, link)\n  664  \n  665:     # a download dir is specified; let's copy the archive there\n  666      if download_dir and not already_downloaded_path:\n  667          _copy_file(from_path, download_dir, link)\n  ...\n  711      content_type = mimetypes.guess_type(from_path)[0]\n  712  \n  713:     # unpack the archive to the build dir location. even when only downloading\n  714      # archives, they have to be unpacked to parse dependencies\n  715      unpack_file(from_path, location, content_type, link)\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/exceptions.py:\n  153      def __init__(self, gotten_hash):\n  154          \"\"\"\n  155:         :param gotten_hash: The hash of the (possibly malicious) archive we\n  156              just downloaded\n  157          \"\"\"\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/index.py:\n  415          search = Search(project_name, canonical_name, formats)\n  416          find_links_versions = self._package_versions(\n  417:             # We trust every directly linked archive in find_links\n  418              (Link(url, '-f') for url in self.find_links),\n  419              search\n  ...\n  616              if ext not in SUPPORTED_EXTENSIONS:\n  617                  self._log_skipped_link(\n  618:                     link, 'unsupported archive format: %s' % ext)\n  619                  return\n  620              if \"binary\" not in search.formats and ext == wheel_ext:\n  ...\n  796  \n  797              # The check for archives above only works if the url ends with\n  798:             # something that looks like an archive. However that is not a\n  799              # requirement of an url. Unless we issue a HEAD request on every\n  800              # url we cannot know ahead of time for sure if something is HTML\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/req/req_install.py:\n  771              )\n  772  \n  773:     def archive(self, build_dir):\n  774          assert self.source_dir\n  775          create_archive = True\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/req/req_set.py:\n  505          with indent_log():\n  506              # ################################ #\n  507:             # # vcs update or unpack archive # #\n  508              # ################################ #\n  509              if req_to_install.editable:\n  ...\n  518                  abstract_dist.prep_for_dist()\n  519                  if self.is_download:\n  520:                     req_to_install.archive(self.download_dir)\n  521                  req_to_install.check_if_exists()\n  522              elif req_to_install.satisfied_by:\n  ...\n  636                      # Make a .zip of the source_dir we already created.\n  637                      if req_to_install.link.scheme in vcs.all_schemes:\n  638:                         req_to_install.archive(self.download_dir)\n  639                  # req_to_install.req is only avail after unpack for URL\n  640                  # pkgs repeat check_if_exists to uninstall-on-upgrade\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/utils/__init__.py:\n  223  def has_leading_dir(paths):\n  224      \"\"\"Returns true if all the paths have the same leading path name\n  225:     (i.e., everything is in one subdirectory in an archive)\"\"\"\n  226      common_prefix = None\n  227      for path in paths:\n  ...\n  614          logger.critical(\n  615              'Cannot unpack file %s (downloaded from %s, content-type: %s); '\n  616:             'cannot detect archive format',\n  617              filename, location, content_type,\n  618          )\n  619          raise InstallationError(\n  620:             'Cannot determine archive format of %s' % location\n  621          )\n  622  \n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/vcs/mercurial.py:\n   26          try:\n   27              self.run_command(\n   28:                 ['archive', location], show_stdout=False, cwd=temp_dir)\n   29          finally:\n   30              rmtree(temp_dir)\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pip/wheel.py:\n  277  \n  278      def record_installed(srcfile, destfile, modified=False):\n  279:         \"\"\"Map archive RECORD paths to installation RECORD paths.\"\"\"\n  280          oldpath = normpath(srcfile, wheeldir)\n  281          newpath = normpath(destfile, lib_dir)\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pkg_resources/__init__.py:\n 1698      def _setup_prefix(self):\n 1699          # we assume here that our metadata may be nested inside a \"basket\"\n 1700:         # of multiple eggs; that's why we use module_path instead of .archive\n 1701          path = self.module_path\n 1702          old = None\n ....\n 1824      def __init__(self, module):\n 1825          EggProvider.__init__(self, module)\n 1826:         self.zip_pre = self.loader.archive+os.sep\n 1827  \n 1828      def _zipinfo_name(self, fspath):\n 1829          # Convert a virtual filename (full path to file) into a zipfile subpath\n 1830:         # usable with the zipimport directory cache for our target archive\n 1831          if fspath.startswith(self.zip_pre):\n 1832              return fspath[len(self.zip_pre):]\n ....\n 1847      @property\n 1848      def zipinfo(self):\n 1849:         return self._zip_manifests.load(self.loader.archive)\n 1850  \n 1851      def get_resource_filename(self, manager, resource_name):\n ....\n 2044          \"\"\"Create a metadata provider from a zipimporter\"\"\"\n 2045  \n 2046:         self.zip_pre = importer.archive+os.sep\n 2047          self.loader = importer\n 2048          if importer.prefix:\n 2049:             self.module_path = os.path.join(importer.archive, importer.prefix)\n 2050          else:\n 2051:             self.module_path = importer.archive\n 2052          self._setup_prefix()\n 2053  \n ....\n 2074      Find eggs in zip files; possibly multiple nested eggs.\n 2075      \"\"\"\n 2076:     if importer.archive.endswith('.whl'):\n 2077          # wheels are not supported with this finder\n 2078          # they don't have PKG-INFO metadata, and won't ever contain eggs\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pygments/lexers/_lasso_builtins.py:\n 3210          'appstatus',\n 3211          'arc',\n 3212:         'archive',\n 3213          'arguments',\n 3214          'argumentvalue',\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/pygments/lexers/installers.py:\n   94               r'XPStyle)\\b', Keyword),\n   95              (r'\\b(CUR|END|(?:FILE_ATTRIBUTE_)?'\n   96:              r'(?:ARCHIVE|HIDDEN|NORMAL|OFFLINE|READONLY|SYSTEM|TEMPORARY)|'\n   97               r'HK(CC|CR|CU|DD|LM|PD|U)|'\n   98               r'HKEY_(?:CLASSES_ROOT|CURRENT_(?:CONFIG|USER)|DYN_DATA|'\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/setuptools/archive_util.py:\n    1: \"\"\"Utilities for extracting common archive formats\"\"\"\n    2  \n    3  \n    .\n   17  \n   18  class UnrecognizedFormat(DistutilsError):\n   19:     \"\"\"Couldn't recognize the archive type\"\"\"\n   20  \n   21  def default_filter(src,dst):\n   ..\n   29  \n   30      `progress_filter` is a function taking two arguments: a source path\n   31:     internal to the archive ('/'-separated), and a filesystem path where it\n   32      will be extracted.  The callback must return the desired extract path\n   33      (which may be the same as the one passed in), or else ``None`` to skip\n   ..\n   39      same signature as this function (minus the `drivers` argument), that raise\n   40      ``UnrecognizedFormat`` if they do not support extracting the designated\n   41:     archive type.  The `drivers` are tried in sequence until one is found that\n   42      does not raise an error, or until all are exhausted (in which case\n   43      ``UnrecognizedFormat`` is raised).  If you do not supply a sequence of\n   ..\n   55      else:\n   56          raise UnrecognizedFormat(\n   57:             \"Not a recognized archive type: %s\" % filename\n   58          )\n   59  \n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/setuptools/command/bdist_egg.py:\n   65          ('keep-temp', 'k',\n   66           \"keep the pseudo-installation tree around after \" +\n   67:          \"creating the distribution archive\"),\n   68          ('dist-dir=', 'd',\n   69           \"directory to put final built distributions in\"),\n   ..\n  218              self.zap_pyfiles()\n  219  \n  220:         # Make the archive\n  221          make_zipfile(self.egg_output, archive_root, verbose=self.verbose,\n  222                       dry_run=self.dry_run, mode=self.gen_header())\n  ...\n  241          if safe is not None:\n  242              return safe\n  243:         log.warn(\"zip_safe flag not set; analyzing archive contents...\")\n  244          return analyze_egg(self.bdist_dir, self.stubs)\n  245  \n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/setuptools/command/easy_install.py:\n 1631      original distribution, are left behind, they can fail to load modules from\n 1632      the replacement distribution. E.g. if an old zipimport.zipimporter instance\n 1633:     is used to load data from a new zipped egg archive, it may cause the\n 1634      operation to attempt to locate the requested data in the wrong location -\n 1635:     one indicated by the original distribution's zip archive directory\n 1636      information. Such an operation may then fail outright, e.g. report having\n 1637      read a 'bad local file header', or even worse, it may fail silently &\n 1638      return invalid data.\n 1639  \n 1640:     zipimport._zip_directory_cache contains cached zip archive directory\n 1641      information for all existing zipimport.zipimporter instances and all such\n 1642:     instances connected to the same archive share the same cached directory\n 1643      information.\n 1644  \n ....\n 1646      all existing zipimport.zipimporter instances instead of having to track\n 1647      them down and remove them one by one, by updating their shared cached zip\n 1648:     archive directory information. This, of course, assumes that the\n 1649      replacement distribution is packaged as a zipped egg.\n 1650  \n ....\n 1679          # Here, even though we do not want to fix existing and now stale\n 1680          # zipimporter cache information, we still want to remove it. Related to\n 1681:         # Python's zip archive directory information cache, we clear each of\n 1682          # its stale entries in two phases:\n 1683:         #   1. Clear the entry so attempting to access zip archive information\n 1684          #      via any existing stale zipimport.zipimporter instances fails.\n 1685          #   2. Remove the entry from the cache so any newly constructed\n 1686          #      zipimport.zipimporter instances do not end up using old stale\n 1687:         #      zip archive directory information.\n 1688          # This whole stale data removal step does not seem strictly necessary,\n 1689          # but has been left in because it was done before we started replacing\n 1690:         # the zip archive directory information cache content if possible, and\n 1691          # there are no relevant unit tests that we can depend on to tell us if\n 1692          # this is really needed.\n ....\n 1763  # and have PyPy repopulate it as needed. The downside is that if there are any\n 1764  # stale zipimport.zipimporter instances laying around, attempting to use them\n 1765: # will fail due to not having its zip archive directory information available\n 1766: # instead of being automatically corrected to use the new correct zip archive\n 1767  # directory information.\n 1768  if '__pypy__' in sys.builtin_module_names:\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/setuptools/command/sdist.py:\n   29          ('keep-temp', 'k',\n   30           \"keep the distribution tree around after creating \" +\n   31:          \"archive file(s)\"),\n   32          ('dist-dir=', 'd',\n   33:          \"directory to put the source distribution archive(s) in \"\n   34           \"[default: dist]\"),\n   35      ]\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/setuptools/package_index.py:\n  136      # to match a request for it.  It's still a potential problem, though, and\n  137      # in the long run PyPI and the distutils should go for \"safe\" names and\n  138:     # versions in distribution archive names (sdist and bdist).\n  139  \n  140      parts = basename.split('-')\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/sqlparse/keywords.py:\n  693  \n  694  KEYWORDS_ORACLE = {\n  695:     'ARCHIVE': tokens.Keyword,\n  696      'ARCHIVELOG': tokens.Keyword,\n  697  \n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/wheel/archive.py:\n    1  \"\"\"\n    2: Archive tools for wheel.\n    3  \"\"\"\n    4  \n    .\n   13  \n   14  def archive_wheelfile(base_name, base_dir):\n   15:     '''Archive all files under `base_dir` in a whl file and name it like\n   16      `base_name`.\n   17      '''\n   ..\n   28      \"\"\"Create a whl file from all the files under 'base_dir'.\n   29  \n   30:     Places .dist-info at the end of the archive.\"\"\"\n   31  \n   32      zip_filename = base_name + \".whl\"\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/wheel/bdist_wheel.py:\n    2  Create a wheel (.whl) distribution.\n    3  \n    4: A wheel is a built archive format.\n    5  \"\"\"\n    6  \n    .\n   36  from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n   37  from .util import native, open_for_csv\n   38: from .archive import archive_wheelfile\n   39  from .pkginfo import read_pkg_info, write_pkg_info\n   40  from .metadata import pkginfo_to_dict\n   ..\n   58                      ('keep-temp', 'k',\n   59                       \"keep the pseudo-installation tree around after \" +\n   60:                      \"creating the distribution archive\"),\n   61                      ('dist-dir=', 'd',\n   62                       \"directory to put final built distributions in\"),\n   ..\n   64                       \"skip rebuilding everything (for testing/debugging)\"),\n   65                      ('relative', None,\n   66:                      \"build the archive using relative paths\"\n   67                       \"(default: false)\"),\n   68                      ('owner=', 'u',\n   ..\n  161  \n  162      def get_archive_basename(self):\n  163:         \"\"\"Return archive name without extension\"\"\"\n  164  \n  165          impl_tag, abi_tag, plat_tag = self.get_tag()\n  ...\n  192          install_scripts.no_ep = True\n  193  \n  194:         # Use a custom scheme for the archive, because we have to decide\n  195          # at installation time which scheme to use.\n  196          for key in ('headers', 'scripts', 'data', 'purelib', 'platlib'):\n  ...\n  236          self.write_record(self.bdist_dir, self.distinfo_dir)\n  237  \n  238:         # Make the archive\n  239          if not os.path.exists(self.dist_dir):\n  240              os.makedirs(self.dist_dir)\n  241          wheel_name = archive_wheelfile(pseudoinstall_root, archive_root)\n  242  \n  243:         # Sign the archive\n  244          if 'WHEEL_TOOL' in os.environ:\n  245              subprocess.call([os.environ['WHEEL_TOOL'], 'sign', wheel_name])\n  ...\n  352              # There is no egg-info. This is probably because the egg-info\n  353              # file/directory is not named matching the distribution name used\n  354:             # to name the archive file. Check for this case and report\n  355              # accordingly.\n  356              import glob\n  ...\n  360              if possible:\n  361                  alt = os.path.basename(possible[0])\n  362:                 err += \" (%s found - possible misnamed archive file?)\" % (alt,)\n  363  \n  364              raise ValueError(err)\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/wheel/install.py:\n   70          \"\"\"\n   71          :param fp: A seekable file-like object or None to open(filename).\n   72:         :param append: Open archive in append mode.\n   73          :param context: Function returning list of supported tags. Wheels\n   74          must have the same context to be sortable.\n   ..\n  271              root = get_path('platlib')\n  272  \n  273:         # Parse all the names in the archive\n  274          name_trans = {}\n  275          for info in self.zipfile.infolist():\n  ...\n  370          and setting expected hashes for every hash in RECORD.\n  371          Caller must complete the verification process by completely reading \n  372:         every file in the archive (e.g. with extractall).\"\"\"\n  373          sig = None\n  374          if zipfile is None:\n  ...\n  473          if not self.fp:\n  474              raise RuntimeError(\n  475:                   \"Attempt to pop from ZIP archive that was already closed\")\n  476          last = self.infolist().pop()\n  477          del self.NameToInfo[last.filename]\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/wheel/test/test_wheelfile.py:\n    1  import os\n    2  import wheel.install\n    3: import wheel.archive\n    4  import hashlib\n    5  try:\n    .\n  117          # The earliest date representable in TarInfos, 1980-01-01\n  118          with environ('SOURCE_DATE_EPOCH', '315576060'):\n  119:             zip_filename = wheel.archive.make_wheelfile_inner(\n  120                  zip_base_name, tempdir)\n  121          with readable_zipfile(zip_filename) as zf:\n  ...\n  134              os.chmod(path, mode)\n  135          zip_base_name = os.path.join(tempdir, 'dummy')\n  136:         zip_filename = wheel.archive.make_wheelfile_inner(\n  137              zip_base_name, tempdir)\n  138          with readable_zipfile(zip_filename) as zf:\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/wheel/tool/__init__.py:\n   94      Remove RECORD.jws from a wheel by truncating the zip file.\n   95  \n   96:     RECORD.jws must be at the end of the archive. The zip file must be an\n   97:     ordinary archive, with the compressed files and the directory in the same\n   98      order, and without any non-zip content after the truncation point.\n   99      \"\"\"\n  ...\n  102      info = vzf.infolist()\n  103      if not (len(info) and info[-1].filename.endswith('/RECORD.jws')):\n  104:         raise WheelError(\"RECORD.jws not found at end of archive.\")\n  105      vzf.pop()\n  106      vzf.close()\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/wheel/wininst2wheel.py:\n    9  from distutils.archive_util import make_archive\n   10  from shutil import rmtree\n   11: from wheel.archive import archive_wheelfile\n   12  from argparse import ArgumentParser\n   13  from glob import iglob\n   ..\n   91      bdw = zipfile.ZipFile(path)\n   92  \n   93:     # Search for egg-info in the archive\n   94      egginfo_name = None\n   95      for filename in bdw.namelist():\n\n/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/tarfile.py:\n  723  class TarInfo(object):\n  724      \"\"\"Informational class which holds the details about an\n  725:        archive member given by a tar header block.\n  726         TarInfo objects are returned by TarFile.getmember(),\n  727         TarFile.getmembers() and TarFile.gettarinfo() and are\n  ...\n 1394                                  # are passed to the caller as exceptions.\n 1395  \n 1396:     format = DEFAULT_FORMAT     # The format to use when creating an archive.\n 1397  \n 1398      encoding = ENCODING         # Encoding for 8-bit character strings.\n ....\n 1407              tarinfo=None, dereference=None, ignore_zeros=None, encoding=None,\n 1408              errors=\"surrogateescape\", pax_headers=None, debug=None, errorlevel=None):\n 1409:         \"\"\"Open an (uncompressed) tar archive `name'. `mode' is either 'r' to\n 1410:            read from an existing archive, 'a' to append data to an existing\n 1411             file or 'w' to create a new file overwriting an existing one. `mode'\n 1412             defaults to 'r'.\n ....\n 1466          self._loaded = False    # flag if all members have been read\n 1467          self.offset = self.fileobj.tell()\n 1468:                                 # current position in the archive file\n 1469          self.inodes = {}        # dictionary caching the inodes of\n 1470:                                 # archive members already added\n 1471  \n 1472          try:\n ....\n 1476  \n 1477              if self.mode == \"a\":\n 1478:                 # Move to the end of the archive,\n 1479                  # before the first empty block.\n 1480                  while True:\n ....\n 1515      @classmethod\n 1516      def open(cls, name=None, mode=\"r\", fileobj=None, bufsize=RECORDSIZE, **kwargs):\n 1517:         \"\"\"Open a tar archive for reading, writing or appending. Return\n 1518             an appropriate TarFile class.\n 1519  \n ....\n 1604      @classmethod\n 1605      def taropen(cls, name, mode=\"r\", fileobj=None, **kwargs):\n 1606:         \"\"\"Open uncompressed tar archive name for reading or writing.\n 1607          \"\"\"\n 1608          if mode not in (\"r\", \"a\", \"w\", \"x\"):\n ....\n 1612      @classmethod\n 1613      def gzopen(cls, name, mode=\"r\", fileobj=None, compresslevel=9, **kwargs):\n 1614:         \"\"\"Open gzip compressed tar archive name for reading or writing.\n 1615             Appending is not allowed.\n 1616          \"\"\"\n ....\n 1646      @classmethod\n 1647      def bz2open(cls, name, mode=\"r\", fileobj=None, compresslevel=9, **kwargs):\n 1648:         \"\"\"Open bzip2 compressed tar archive name for reading or writing.\n 1649             Appending is not allowed.\n 1650          \"\"\"\n ....\n 1675      @classmethod\n 1676      def xzopen(cls, name, mode=\"r\", fileobj=None, preset=None, **kwargs):\n 1677:         \"\"\"Open lzma compressed tar archive name for reading or writing.\n 1678             Appending is not allowed.\n 1679          \"\"\"\n ....\n 1714      def close(self):\n 1715          \"\"\"Close the TarFile. In write-mode, two finishing zero blocks are\n 1716:            appended to the archive.\n 1717          \"\"\"\n 1718          if self.closed:\n ....\n 1735      def getmember(self, name):\n 1736          \"\"\"Return a TarInfo object for member `name'. If `name' can not be\n 1737:            found in the archive, KeyError is raised. If a member occurs more\n 1738:            than once in the archive, its last occurrence is assumed to be the\n 1739             most up-to-date version.\n 1740          \"\"\"\n ....\n 1745  \n 1746      def getmembers(self):\n 1747:         \"\"\"Return the members of the archive as a list of TarInfo objects. The\n 1748:            list has the same order as the members in the archive.\n 1749          \"\"\"\n 1750          self._check()\n 1751          if not self._loaded:    # if we want to obtain a list of\n 1752              self._load()        # all members, we first have to\n 1753:                                 # scan the whole archive.\n 1754          return self.members\n 1755  \n 1756      def getnames(self):\n 1757:         \"\"\"Return the members of the archive as a list of their names. It has\n 1758             the same order as the list returned by getmembers().\n 1759          \"\"\"\n ....\n 1765             modify some of the TarInfo's attributes before you add it using\n 1766             addfile(). If given, `arcname' specifies an alternative name for the\n 1767:            file in the archive.\n 1768          \"\"\"\n 1769          self._check(\"awx\")\n ....\n 1774              name = fileobj.name\n 1775  \n 1776:         # Building the name of the member in the archive.\n 1777          # Backward slashes are converted to forward slashes,\n 1778          # Absolute paths are turned to relative paths.\n ....\n 1891  \n 1892      def add(self, name, arcname=None, recursive=True, exclude=None, *, filter=None):\n 1893:         \"\"\"Add the file `name' to the archive. `name' may be any type of file\n 1894             (directory, fifo, symbolic link, etc.). If given, `arcname'\n 1895:            specifies an alternative name for the file in the archive.\n 1896             Directories are added recursively by default. This can be avoided by\n 1897             setting `recursive' to False. `exclude' is a function that should\n ....\n 1899             that expects a TarInfo object argument and returns the changed\n 1900             TarInfo object, if it returns None the TarInfo object will be\n 1901:            excluded from the archive.\n 1902          \"\"\"\n 1903          self._check(\"awx\")\n ....\n 1915                  return\n 1916  \n 1917:         # Skip if somebody tries to archive the archive...\n 1918          if self.name is not None and os.path.abspath(name) == self.name:\n 1919              self._dbg(2, \"tarfile: Skipped %r\" % name)\n ....\n 1936                  return\n 1937  \n 1938:         # Append the tar header and data to the archive.\n 1939          if tarinfo.isreg():\n 1940              with bltn_open(name, \"rb\") as f:\n ....\n 1952  \n 1953      def addfile(self, tarinfo, fileobj=None):\n 1954:         \"\"\"Add the TarInfo object `tarinfo' to the archive. If `fileobj' is\n 1955:            given, tarinfo.size bytes are read from it and added to the archive.\n 1956             You can create TarInfo objects using gettarinfo().\n 1957             On Windows platforms, `fileobj' should always be opened with mode\n ....\n 1978  \n 1979      def extractall(self, path=\".\", members=None, *, numeric_owner=False):\n 1980:         \"\"\"Extract all members from the archive to the current working\n 1981             directory and set owner, modification time and permissions on\n 1982             directories afterwards. `path' specifies a different directory\n ....\n 2018  \n 2019      def extract(self, member, path=\"\", set_attrs=True, *, numeric_owner=False):\n 2020:         \"\"\"Extract a member from the archive to the current working directory,\n 2021             using its full name. Its file information is extracted as accurately\n 2022             as possible. `member' may be a filename or a TarInfo object. You can\n ....\n 2056  \n 2057      def extractfile(self, member):\n 2058:         \"\"\"Extract a member from the archive as a file object. `member' may be\n 2059             a filename or a TarInfo object. If `member' is a regular file or a\n 2060             link, an io.BufferedReader object is returned. Otherwise, None is\n ....\n 2100          upperdirs = os.path.dirname(targetpath)\n 2101          if upperdirs and not os.path.exists(upperdirs):\n 2102:             # Create directories that are not part of the archive with\n 2103              # default permissions.\n 2104              os.makedirs(upperdirs)\n ....\n 2212                                       targetpath)\n 2213              except KeyError:\n 2214:                 raise ExtractError(\"unable to resolve link inside archive\")\n 2215  \n 2216      def chown(self, tarinfo, targetpath, numeric_owner):\n ....\n 2261      #--------------------------------------------------------------------------\n 2262      def next(self):\n 2263:         \"\"\"Return the next member of the archive as a TarInfo object, when\n 2264             TarFile is opened for reading. Return None if there is no more\n 2265             available.\n ....\n 2315  \n 2316      def _getmember(self, name, tarinfo=None, normalize=False):\n 2317:         \"\"\"Find an archive member by name from bottom to top.\n 2318             If tarinfo is given, it is used as the starting point.\n 2319          \"\"\"\n ....\n 2338  \n 2339      def _load(self):\n 2340:         \"\"\"Read through the entire archive file and look for readable\n 2341             members.\n 2342          \"\"\"\n ....\n 2358      def _find_link_target(self, tarinfo):\n 2359          \"\"\"Find the target member of a symlink or hardlink member in the\n 2360:            archive.\n 2361          \"\"\"\n 2362          if tarinfo.issym():\n 2363:             # Always search the entire archive.\n 2364              linkname = \"/\".join(filter(None, (os.path.dirname(tarinfo.name), tarinfo.linkname)))\n 2365              limit = None\n 2366          else:\n 2367:             # Search the archive before the link, because a hard link is\n 2368              # just a reference to an already archived file.\n 2369              linkname = tarinfo.linkname\n ....\n 2398          else:\n 2399              # An exception occurred. We must not call close() because\n 2400:             # it would try to write end-of-archive blocks and padding.\n 2401              if not self._extfileobj:\n 2402                  self.fileobj.close()\n ....\n 2446  #--------------------\n 2447  def is_tarfile(name):\n 2448:     \"\"\"Return True if name points to a tar archive that we\n 2449         are able to handle, else return False.\n 2450      \"\"\"\n ....\n 2486                  print(tar.getmembers(), file=sys.stderr)\n 2487              if args.verbose:\n 2488:                 print('{!r} is a tar archive.'.format(src))\n 2489          else:\n 2490:             parser.exit(1, '{!r} is not a tar archive.\\n'.format(src))\n 2491  \n 2492      elif args.list:\n ....\n 2496                  tf.list(verbose=args.verbose)\n 2497          else:\n 2498:             parser.exit(1, '{!r} is not a tar archive.\\n'.format(src))\n 2499  \n 2500      elif args.extract:\n ....\n 2518                  print(msg)\n 2519          else:\n 2520:             parser.exit(1, '{!r} is not a tar archive.\\n'.format(src))\n 2521  \n 2522      elif args.create:\n\n/home/webdev/work/python/mywebmarks-backend/requirements/twisted/Twisted-17.1.0/build/lib.linux-x86_64-3.5/twisted/python/modules.py:\n  450  \n  451      @ivar filePath: a FilePath-like object pointing at the filesystem location\n  452:     or archive file where this path entry is stored.\n  453  \n  454      @ivar pythonPath: a PythonPath instance.\n  ...\n  505          \"\"\"\n  506          Map the given FS path to a ZipPath, by looking at the ZipImporter's\n  507:         \"archive\" attribute and using it as our ZipArchive root, then walking\n  508:         down into the archive from there.\n  509  \n  510          @return: a L{zippath.ZipPath} or L{zippath.ZipArchive} instance.\n  511          \"\"\"\n  512:         za = ZipArchive(self.importer.archive)\n  513:         myPath = FilePath(self.importer.archive)\n  514          itsPath = FilePath(fsPathString)\n  515          if myPath == itsPath:\n\n/home/webdev/work/python/mywebmarks-backend/requirements/twisted/Twisted-17.1.0/build/lib.linux-x86_64-3.5/twisted/python/test/test_zipstream.py:\n  153      def makeZipFile(self, contents, directory=''):\n  154          \"\"\"\n  155:         Makes a zip file archive containing len(contents) files.  Contents\n  156          should be a list of strings, each string being the content of one file.\n  157          \"\"\"\n  ...\n  188          \"\"\"\n  189          A zipfile entry with the wrong magic number should raise BadZipfile for\n  190:         readfile(), but that should not affect other files in the archive.\n  191          \"\"\"\n  192          fn = self.makeZipFile([\"test contents\",\n  ...\n  258          \"\"\"\n  259          L{twisted.python.zipstream.unzipIterChunky} returns an iterator which\n  260:         must be exhausted to completely unzip the input archive.\n  261          \"\"\"\n  262          numfiles = 10\n  ...\n  278          The path to which a file is extracted by L{zipstream.unzipIterChunky}\n  279          is determined by joining the C{directory} argument to C{unzip} with the\n  280:         path within the archive of the file being extracted.\n  281          \"\"\"\n  282          numfiles = 10\n  ...\n  333          \"\"\"\n  334          unzipIterChunky should unzip the given number of bytes per iteration on\n  335:         a stored archive.\n  336          \"\"\"\n  337          self._unzipIterChunkyTest(zipfile.ZIP_STORED, 500, 35, 45)\n  ...\n  341          \"\"\"\n  342          unzipIterChunky should unzip the given number of bytes per iteration on\n  343:         a deflated archive.\n  344          \"\"\"\n  345          self._unzipIterChunkyTest(zipfile.ZIP_DEFLATED, 972, 23, 27)\n\n/home/webdev/work/python/mywebmarks-backend/requirements/twisted/Twisted-17.1.0/build/lib.linux-x86_64-3.5/twisted/python/zippath.py:\n   35      \"\"\"\n   36  \n   37:     def __init__(self, archive, pathInArchive):\n   38          \"\"\"\n   39          Don't construct me directly.  Use C{ZipArchive.child()}.\n   40  \n   41:         @param archive: a L{ZipArchive} instance.\n   42  \n   43          @param pathInArchive: a ZIP_PATH_SEP-separated string.\n   44          \"\"\"\n   45:         self.archive = archive\n   46          self.pathInArchive = pathInArchive\n   47  \n   ..\n   50          sep = _coerceToFilesystemEncoding(pathInArchive, ZIP_PATH_SEP)\n   51          archiveFilename = _coerceToFilesystemEncoding(\n   52:             pathInArchive, archive.zipfile.filename)\n   53          self.path = os.path.join(archiveFilename,\n   54                                   *(self.pathInArchive.split(sep)))\n   ..\n   58          if not isinstance(other, ZipPath):\n   59              return NotImplemented\n   60:         return cmp((self.archive, self.pathInArchive),\n   61:                    (other.archive, other.pathInArchive))\n   62  \n   63  \n   64      def __repr__(self):\n   65          parts = [_coerceToFilesystemEncoding(\n   66:             self.sep, os.path.abspath(self.archive.path))]\n   67          parts.extend(self.pathInArchive.split(self.sep))\n   68          ossep = _coerceToFilesystemEncoding(self.sep, os.sep)\n   ..\n   84          splitup = self.pathInArchive.split(self.sep)\n   85          if len(splitup) == 1:\n   86:             return self.archive\n   87:         return ZipPath(self.archive, self.sep.join(splitup[:-1]))\n   88  \n   89  \n   90      def child(self, path):\n   91          \"\"\"\n   92:         Return a new ZipPath representing a path in C{self.archive} which is\n   93          a child of this path.\n   94  \n   95          @note: Requesting the C{\"..\"} (or other special name) child will not\n   96              cause L{InsecurePath} to be raised since these names do not have\n   97:             any special meaning inside a zip archive.  Be particularly\n   98              careful with the C{path} attribute (if you absolutely must use\n   99              it) as this means it may include special names with special\n  100:             meaning outside of the context of a zip archive.\n  101          \"\"\"\n  102          joiner = _coerceToFilesystemEncoding(path, ZIP_PATH_SEP)\n  103          pathInArchive = _coerceToFilesystemEncoding(path, self.pathInArchive)\n  104:         return ZipPath(self.archive, joiner.join([pathInArchive, path]))\n  105  \n  106  \n  ...\n  114  \n  115      def isdir(self):\n  116:         return self.pathInArchive in self.archive.childmap\n  117  \n  118  \n  119      def isfile(self):\n  120:         return self.pathInArchive in self.archive.zipfile.NameToInfo\n  121  \n  122  \n  ...\n  128          if self.exists():\n  129              if self.isdir():\n  130:                 return list(self.archive.childmap[self.pathInArchive].keys())\n  131              else:\n  132                  raise UnlistableError(\n  ...\n  159      def open(self, mode=\"r\"):\n  160          pathInArchive = _coerceToFilesystemEncoding('', self.pathInArchive)\n  161:         return self.archive.zipfile.open(pathInArchive, mode=mode)\n  162  \n  163  \n  ...\n  173          \"\"\"\n  174          pathInArchive = _coerceToFilesystemEncoding(\"\", self.pathInArchive)\n  175:         return self.archive.zipfile.NameToInfo[pathInArchive].file_size\n  176  \n  177  \n  ...\n  179          \"\"\"\n  180          Retrieve this file's last access-time.  This is the same as the last access\n  181:         time for the archive.\n  182  \n  183          @return: a number of seconds since the epoch\n  184          \"\"\"\n  185:         return self.archive.getAccessTime()\n  186  \n  187  \n  ...\n  195          pathInArchive = _coerceToFilesystemEncoding(\"\", self.pathInArchive)\n  196          return time.mktime(\n  197:             self.archive.zipfile.NameToInfo[pathInArchive].date_time\n  198              + (0, 0, 0))\n  199  \n  ...\n  212  class ZipArchive(ZipPath):\n  213      \"\"\"\n  214:     I am a L{FilePath}-like object which can wrap a zip archive as if it were a\n  215      directory.\n  216  \n  ...\n  222      converting if required.\n  223      \"\"\"\n  224:     archive = property(lambda self: self)\n  225  \n  226      def __init__(self, archivePathname):\n  227          \"\"\"\n  228:         Create a ZipArchive, treating the archive at archivePathname as a zip\n  229          file.\n  230  \n  ...\n  253      def child(self, path):\n  254          \"\"\"\n  255:         Create a ZipPath pointing at a path within the archive.\n  256  \n  257          @param path: a L{bytes} or L{unicode} with no path separators in it\n  ...\n  263      def exists(self):\n  264          \"\"\"\n  265:         Returns C{True} if the underlying archive exists.\n  266          \"\"\"\n  267          return FilePath(self.zipfile.filename).exists()\n  ...\n  270      def getAccessTime(self):\n  271          \"\"\"\n  272:         Return the archive file's last access time.\n  273          \"\"\"\n  274          return FilePath(self.zipfile.filename).getAccessTime()\n  ...\n  277      def getModificationTime(self):\n  278          \"\"\"\n  279:         Return the archive file's modification time.\n  280          \"\"\"\n  281          return FilePath(self.zipfile.filename).getModificationTime()\n  ...\n  284      def getStatusChangeTime(self):\n  285          \"\"\"\n  286:         Return the archive file's status change time.\n  287          \"\"\"\n  288          return FilePath(self.zipfile.filename).getStatusChangeTime()\n\n/home/webdev/work/python/mywebmarks-backend/requirements/twisted/Twisted-17.1.0/build/lib.linux-x86_64-3.5/twisted/python/zipstream.py:\n   30          if not self.fp:\n   31              raise RuntimeError(\n   32:                 \"Attempt to read ZIP archive that was already closed\")\n   33          zinfo = self.getinfo(name)\n   34  \n   ..\n   71      \"\"\"\n   72      Abstract superclass of both compressed and uncompressed variants of\n   73:     file-like objects within a zip archive.\n   74  \n   75      @ivar chunkingZipFile: a chunking zip file.\n   ..\n  277  \n  278      @param zipinfo: a C{zipfile.ZipInfo} instance describing an entry in a zip\n  279:     archive to be counted.\n  280  \n  281      @return: the number of chunks present in the zip file.  (Even an empty file\n\n/home/webdev/work/python/mywebmarks-backend/requirements/twisted/Twisted-17.1.0/src/twisted/python/modules.py:\n  450  \n  451      @ivar filePath: a FilePath-like object pointing at the filesystem location\n  452:     or archive file where this path entry is stored.\n  453  \n  454      @ivar pythonPath: a PythonPath instance.\n  ...\n  505          \"\"\"\n  506          Map the given FS path to a ZipPath, by looking at the ZipImporter's\n  507:         \"archive\" attribute and using it as our ZipArchive root, then walking\n  508:         down into the archive from there.\n  509  \n  510          @return: a L{zippath.ZipPath} or L{zippath.ZipArchive} instance.\n  511          \"\"\"\n  512:         za = ZipArchive(self.importer.archive)\n  513:         myPath = FilePath(self.importer.archive)\n  514          itsPath = FilePath(fsPathString)\n  515          if myPath == itsPath:\n\n/home/webdev/work/python/mywebmarks-backend/requirements/twisted/Twisted-17.1.0/src/twisted/python/test/test_zipstream.py:\n  153      def makeZipFile(self, contents, directory=''):\n  154          \"\"\"\n  155:         Makes a zip file archive containing len(contents) files.  Contents\n  156          should be a list of strings, each string being the content of one file.\n  157          \"\"\"\n  ...\n  188          \"\"\"\n  189          A zipfile entry with the wrong magic number should raise BadZipfile for\n  190:         readfile(), but that should not affect other files in the archive.\n  191          \"\"\"\n  192          fn = self.makeZipFile([\"test contents\",\n  ...\n  258          \"\"\"\n  259          L{twisted.python.zipstream.unzipIterChunky} returns an iterator which\n  260:         must be exhausted to completely unzip the input archive.\n  261          \"\"\"\n  262          numfiles = 10\n  ...\n  278          The path to which a file is extracted by L{zipstream.unzipIterChunky}\n  279          is determined by joining the C{directory} argument to C{unzip} with the\n  280:         path within the archive of the file being extracted.\n  281          \"\"\"\n  282          numfiles = 10\n  ...\n  333          \"\"\"\n  334          unzipIterChunky should unzip the given number of bytes per iteration on\n  335:         a stored archive.\n  336          \"\"\"\n  337          self._unzipIterChunkyTest(zipfile.ZIP_STORED, 500, 35, 45)\n  ...\n  341          \"\"\"\n  342          unzipIterChunky should unzip the given number of bytes per iteration on\n  343:         a deflated archive.\n  344          \"\"\"\n  345          self._unzipIterChunkyTest(zipfile.ZIP_DEFLATED, 972, 23, 27)\n\n/home/webdev/work/python/mywebmarks-backend/requirements/twisted/Twisted-17.1.0/src/twisted/python/zippath.py:\n   35      \"\"\"\n   36  \n   37:     def __init__(self, archive, pathInArchive):\n   38          \"\"\"\n   39          Don't construct me directly.  Use C{ZipArchive.child()}.\n   40  \n   41:         @param archive: a L{ZipArchive} instance.\n   42  \n   43          @param pathInArchive: a ZIP_PATH_SEP-separated string.\n   44          \"\"\"\n   45:         self.archive = archive\n   46          self.pathInArchive = pathInArchive\n   47  \n   ..\n   50          sep = _coerceToFilesystemEncoding(pathInArchive, ZIP_PATH_SEP)\n   51          archiveFilename = _coerceToFilesystemEncoding(\n   52:             pathInArchive, archive.zipfile.filename)\n   53          self.path = os.path.join(archiveFilename,\n   54                                   *(self.pathInArchive.split(sep)))\n   ..\n   58          if not isinstance(other, ZipPath):\n   59              return NotImplemented\n   60:         return cmp((self.archive, self.pathInArchive),\n   61:                    (other.archive, other.pathInArchive))\n   62  \n   63  \n   64      def __repr__(self):\n   65          parts = [_coerceToFilesystemEncoding(\n   66:             self.sep, os.path.abspath(self.archive.path))]\n   67          parts.extend(self.pathInArchive.split(self.sep))\n   68          ossep = _coerceToFilesystemEncoding(self.sep, os.sep)\n   ..\n   84          splitup = self.pathInArchive.split(self.sep)\n   85          if len(splitup) == 1:\n   86:             return self.archive\n   87:         return ZipPath(self.archive, self.sep.join(splitup[:-1]))\n   88  \n   89  \n   90      def child(self, path):\n   91          \"\"\"\n   92:         Return a new ZipPath representing a path in C{self.archive} which is\n   93          a child of this path.\n   94  \n   95          @note: Requesting the C{\"..\"} (or other special name) child will not\n   96              cause L{InsecurePath} to be raised since these names do not have\n   97:             any special meaning inside a zip archive.  Be particularly\n   98              careful with the C{path} attribute (if you absolutely must use\n   99              it) as this means it may include special names with special\n  100:             meaning outside of the context of a zip archive.\n  101          \"\"\"\n  102          joiner = _coerceToFilesystemEncoding(path, ZIP_PATH_SEP)\n  103          pathInArchive = _coerceToFilesystemEncoding(path, self.pathInArchive)\n  104:         return ZipPath(self.archive, joiner.join([pathInArchive, path]))\n  105  \n  106  \n  ...\n  114  \n  115      def isdir(self):\n  116:         return self.pathInArchive in self.archive.childmap\n  117  \n  118  \n  119      def isfile(self):\n  120:         return self.pathInArchive in self.archive.zipfile.NameToInfo\n  121  \n  122  \n  ...\n  128          if self.exists():\n  129              if self.isdir():\n  130:                 return list(self.archive.childmap[self.pathInArchive].keys())\n  131              else:\n  132                  raise UnlistableError(\n  ...\n  159      def open(self, mode=\"r\"):\n  160          pathInArchive = _coerceToFilesystemEncoding('', self.pathInArchive)\n  161:         return self.archive.zipfile.open(pathInArchive, mode=mode)\n  162  \n  163  \n  ...\n  173          \"\"\"\n  174          pathInArchive = _coerceToFilesystemEncoding(\"\", self.pathInArchive)\n  175:         return self.archive.zipfile.NameToInfo[pathInArchive].file_size\n  176  \n  177  \n  ...\n  179          \"\"\"\n  180          Retrieve this file's last access-time.  This is the same as the last access\n  181:         time for the archive.\n  182  \n  183          @return: a number of seconds since the epoch\n  184          \"\"\"\n  185:         return self.archive.getAccessTime()\n  186  \n  187  \n  ...\n  195          pathInArchive = _coerceToFilesystemEncoding(\"\", self.pathInArchive)\n  196          return time.mktime(\n  197:             self.archive.zipfile.NameToInfo[pathInArchive].date_time\n  198              + (0, 0, 0))\n  199  \n  ...\n  212  class ZipArchive(ZipPath):\n  213      \"\"\"\n  214:     I am a L{FilePath}-like object which can wrap a zip archive as if it were a\n  215      directory.\n  216  \n  ...\n  222      converting if required.\n  223      \"\"\"\n  224:     archive = property(lambda self: self)\n  225  \n  226      def __init__(self, archivePathname):\n  227          \"\"\"\n  228:         Create a ZipArchive, treating the archive at archivePathname as a zip\n  229          file.\n  230  \n  ...\n  253      def child(self, path):\n  254          \"\"\"\n  255:         Create a ZipPath pointing at a path within the archive.\n  256  \n  257          @param path: a L{bytes} or L{unicode} with no path separators in it\n  ...\n  263      def exists(self):\n  264          \"\"\"\n  265:         Returns C{True} if the underlying archive exists.\n  266          \"\"\"\n  267          return FilePath(self.zipfile.filename).exists()\n  ...\n  270      def getAccessTime(self):\n  271          \"\"\"\n  272:         Return the archive file's last access time.\n  273          \"\"\"\n  274          return FilePath(self.zipfile.filename).getAccessTime()\n  ...\n  277      def getModificationTime(self):\n  278          \"\"\"\n  279:         Return the archive file's modification time.\n  280          \"\"\"\n  281          return FilePath(self.zipfile.filename).getModificationTime()\n  ...\n  284      def getStatusChangeTime(self):\n  285          \"\"\"\n  286:         Return the archive file's status change time.\n  287          \"\"\"\n  288          return FilePath(self.zipfile.filename).getStatusChangeTime()\n\n/home/webdev/work/python/mywebmarks-backend/requirements/twisted/Twisted-17.1.0/src/twisted/python/zipstream.py:\n   30          if not self.fp:\n   31              raise RuntimeError(\n   32:                 \"Attempt to read ZIP archive that was already closed\")\n   33          zinfo = self.getinfo(name)\n   34  \n   ..\n   71      \"\"\"\n   72      Abstract superclass of both compressed and uncompressed variants of\n   73:     file-like objects within a zip archive.\n   74  \n   75      @ivar chunkingZipFile: a chunking zip file.\n   ..\n  277  \n  278      @param zipinfo: a C{zipfile.ZipInfo} instance describing an entry in a zip\n  279:     archive to be counted.\n  280  \n  281      @return: the number of chunks present in the zip file.  (Even an empty file\n\n624 matches across 85 files\n\n\nSearching 8377 files for \"ArchiveSerializer\" (whole word)\n\n/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/viewsets.py:\n  150          bookmark.archive_id = archive.id\n  151          bookmark.save()\n  152:         serializer = ArchiveSerializer(archive)\n  153          return Response(serializer.data)\n  154  \n\n1 match in 1 file\n",
			"settings":
			{
				"buffer_size": 127968,
				"line_ending": "Unix",
				"name": "Find Results",
				"scratch": true
			}
		}
	],
	"build_system": "",
	"build_system_choices":
	[
	],
	"build_varint": "",
	"command_palette":
	{
		"height": 57.0,
		"last_filter": "FileDiffs",
		"selected_items":
		[
			[
				"FileDiffs",
				"FileDiffs: Menu"
			],
			[
				"",
				"Anaconda: Goto object definition"
			],
			[
				"an",
				"Anaconda: Goto object definition"
			],
			[
				"ana",
				"Anaconda: Autoformat PEP8 Errors"
			],
			[
				"Package Control: ",
				"Package Control: Upgrade Package"
			],
			[
				"Ens",
				"Ensime: Project"
			],
			[
				"pa",
				"Package Control: Install Package"
			],
			[
				"inde",
				"Indentation: Reindent Lines"
			],
			[
				"git",
				"GitGutter: Compare Against Branch"
			],
			[
				"co",
				"Package Control: Install Package"
			]
		],
		"width": 451.0
	},
	"console":
	{
		"height": 110.0,
		"history":
		[
			"import urllib.request,os,hashlib; h = '2915d1851351e5ee549c20394736b442' + '8bc59f460fa1548d1514676163dafc88'; pf = 'Package Control.sublime-package'; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( 'http://packagecontrol.io/' + pf.replace(' ', '%20')).read(); dh = hashlib.sha256(by).hexdigest(); print('Error validating download (got %s instead of %s), please try manual install' % (dh, h)) if dh != h else open(os.path.join( ipp, pf), 'wb' ).write(by) ",
			"print(\"t\")",
			"print(t)",
			"print \"t\"",
			"print t",
			"ls"
		]
	},
	"distraction_free":
	{
		"menu_visible": true,
		"show_minimap": false,
		"show_open_files": false,
		"show_tabs": false,
		"side_bar_visible": false,
		"status_bar_visible": false
	},
	"expanded_folders":
	[
		"/home/webdev/work/python/mywebmarks-backend",
		"/home/webdev/work/python/mywebmarks-backend/apps",
		"/home/webdev/work/python/mywebmarks-backend/apps/static/rest_framework_swagger",
		"/home/webdev/work/python/mywebmarks-backend/apps/static/rest_framework_swagger/css",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/storage",
		"/home/webdev/work/python/mywebmarks-backend/config/settings",
		"/home/webdev/work/python/mywebmarks-backend/docs/pdf",
		"/home/webdev/work/python/mywebmarks-backend/docs/todo",
		"/home/webdev/work/python/mywebmarks-backend/env/lib",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/django_filters/templates/django_filters",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/django_filters/templates/django_filters/rest_framework",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/django_redis/client",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/faker/providers/address",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/faker/providers/address/cs_CZ",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/faker/providers/barcode/en_US",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/rest_framework_swagger",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/rest_framework_swagger/templates",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/rest_framework_swagger/templates/rest_framework_swagger",
		"/home/webdev/work/python/mywebmarks-backend/run",
		"/home/webdev/work/python/mywebmarks-backend/staticfiles/channels/js",
		"/home/webdev/work/python/mywebmarks-backend/staticfiles/django_extensions",
		"/home/webdev/work/python/mywebmarks-backend/staticfiles/facebook/js"
	],
	"file_history":
	[
		"/home/webdev/Tlchargements/271bd7dc-2ada-48e2-9920-dbca14a57699",
		"/home/webdev/Tlchargements/-www-webmarks-filestore-271bd7dc-2ada-48e2-9920-dbca14a57699-",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/urls.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/serializers.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/crawler/serializers.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/upload/models.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/upload/apps.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/upload/admin.py",
		"/home/webdev/work/python/mywebmarks-backend/makemigrations.sh",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/upload/viewsets.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/upload/urls.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/upload/serializers.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/viewsets.py",
		"/home/webdev/work/python/mywebmarks-backend/docs/todo/todo.txt",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/crawler/viewsets.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/storage/viewsets.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/storage/serializers.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/templates/index.html",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/storage/urls.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/storage/models.py",
		"/home/webdev/work/python/mywebmarks-backend/config/urls.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/storage/apps.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/models.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/base/models.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/notes/viewsets.py",
		"/home/webdev/Tlchargements/-www-webmarks-filestore-fb7d741e-6faf-4723-a041-a921502b5ac7-",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/queryviewset.py",
		"/home/webdev/work/python/mywebmarks-backend/config/settings/common.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/templates/500.html",
		"/home/webdev/work/python/mywebmarks-backend/apps/templates/404.html",
		"/home/webdev/work/python/mywebmarks-backend/apps/templates/base.html",
		"/home/webdev/Tlchargements/-www-webmarks-filestore-7348f4c0-840d-4028-8b2e-416897bd367e- (1)",
		"/home/webdev/work/python/mywebmarks-backend/apps/templates/api/index.html",
		"/home/webdev/work/python/mywebmarks-backend/apps/templates/rest_framework_swagger/index.html",
		"/home/webdev/work/python/mywebmarks-backend/apps/templates/base1.html",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/rest_framework_swagger/templates/rest_framework_swagger/base.html",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/contrib/django/viewsets.py",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/rest_framework/generics.py",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/rest_framework_swagger/renderers.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/apiviews.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/handlers.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/__init__.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/filters.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/uploader/models.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/storage/crawler.py.old",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/apps.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/managers.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/contrib/crawler/crawler.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/contrib/lists.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/contrib/crawler/crawler.py",
		"/home/webdev/Tlchargements/-www-webmarks-filestore-7348f4c0-840d-4028-8b2e-416897bd367e-",
		"/home/webdev/.config/sublime-text-3/Packages/Default/Preferences.sublime-settings",
		"/home/webdev/work/python/mywebmarks-backend/apps/contrib/django/models.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/base/serializers.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/base/filters.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/base/apps.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/uploader/settings.py",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/rest_auth/tests/settings.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/uploader/admin.py",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/Twisted-17.1.0-py3.5-linux-x86_64.egg/twisted/python/context.py",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/Twisted-17.1.0-py3.5-linux-x86_64.egg/twisted/cred/checkers.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/users/tests/factories.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/tests.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/users/apps.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/uploader/apps.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks.uploader/apps.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks.uploader/admin.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/notes/filters.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/storage/models.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks.authentication/apps.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/storage/urls.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/storage/viewsets.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/storage/serializers.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/storage/apps.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/authentication/apps.py",
		"/home/webdev/Tlchargements/-www-webmarks-filestore-1a90963b-666e-466a-87ca-1fff45d1f842-",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/core/filters.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/core/viewsets.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/core/models.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/rest_api_auth/social_account.txt",
		"/home/webdev/work/python/mywebmarks-backend/apps/users/apps.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/upload/migrations/0001_initial.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/core/serializers.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/rest_api_auth/apps.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/notes/apps.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/core/apps.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/hello-srv.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/contrib/serializers.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/utils/storage.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/contrib/crawler.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/signals/handlers.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/contrib/django/viewsets.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/contrib/django/__init__.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/storage/storage.py",
		"/home/webdev/work/python/mywebmarks-backend/requirements/base.txt",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/core/__init__.py",
		"/home/webdev/Tlchargements/-www-webmarks-filestore-6d3335d0-0a3d-48a0-9b03-bfd921cfef2f-",
		"/home/webdev/Tlchargements/-www-webmarks-filestore-1814--4f40---b2d--d-48--2c-b--4fa---4193--5948--9f4c-18144f40-b2dd-482c-b4fa-419359489f4c",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/migrations/0007_auto_20170730_1431.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/migrations/0006_auto_20170730_1428.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/migrations/web",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/migrations/0010_add_uuid_field.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/migrations/0009_auto_20170730_1447.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/migrations/0008_auto_20170730_1437.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/migrations/0011_populate_uuid_values.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/bookmarks/migrations/00012_remove_uuid_null.py",
		"/www/webmarks/filestore/109020128768024892015/0cde2352-3191-4f9a-accd-14ed03f7172c",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/rest_framework/mixins.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/drf_utils/viewsets.py",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/django/views/decorators/csrf.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/rest_auth/permissions.py",
		"/home/webdev/work/python/mywebmarks-backend/compose/webmarks/apache/webmarks.conf",
		"/home/webdev/work/python/mywebmarks-backend/.gitignore",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/drf_utils/paginators.py",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/rest_framework/viewsets.py",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/rest_framework/permissions.py",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/rest_framework/schemas.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/rest_auth/apiviews.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/users/adapters.py",
		"/home/webdev/work/python/mywebmarks-backend/config/settings/local.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/rest_auth/urls.py",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/allauth/account/utils.py",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/allauth/socialaccount/adapter.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/rest_auth/providers/linkedin_oauth2/__init__.py",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/django/contrib/sites/models.py",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/allauth/socialaccount/providers/google/views.py",
		"/home/webdev/work/python/mywebmarks-backend/apps/webmarks/rest_auth/providers/linkedin_oauth2/views.py",
		"/home/webdev/work/python/mywebmarks-backend/env/lib/python3.5/site-packages/allauth/socialaccount/providers/linkedin_oauth2/views.py"
	],
	"find":
	{
		"height": 37.0
	},
	"find_in_files":
	{
		"height": 103.0,
		"where_history":
		[
			"/home/webdev/work/python/mywebmarks-backend,*.py",
			"/home/webdev/work/python/mywebmarks-backend,*.*",
			"/home/webdev/work/python/mywebmarks-backend,*.py",
			"/home/webdev/work/python/mywebmarks-backend,*.html",
			"/home/webdev/work/python/mywebmarks-backend,*.py",
			"/home/webdev/work/python/mywebmarks-backend,*.*",
			"/home/webdev/work/python/mynotes-backend/,*.*",
			"/home/webdev/work/python/mynotes-backend/,*.py",
			"/home/webdev/work/python/mynotes-backend/,*.*",
			"/home/webdev/work/python/mynotes-backend/,*.py",
			"/home/webdev/work/python/mynotes-backend/**.py",
			"/home/webdev/work/python/mynotes-backend",
			"/home/webdev/work/python/mynotes-backend/config",
			"/home/webdev/work/python/mynotes/apps,*.css",
			"/home/webdev/work/python/mynotes/apps",
			"/home/webdev/work/python/mydrive/apps/angular_drive/static/mydrive/assets,*.js",
			"/home/webdev/work/python/mynotes,*.py",
			"/home/webdev/work/python/mynotes,*.*",
			"/home/webdev/work/python/mynotes,*.html",
			"/home/webdev/work/python/mynotes,*.*",
			"/home/webdev/work/python/mynotes,*.html",
			"/home/webdev/work/python/mynotes,*.js",
			"/home/webdev/work/python/mynotes,*.css",
			"/home/webdev/work/python/mynotes,*.py",
			"/home/webdev/work/python/mynotes,*.css",
			"/home/webdev/work/python/mynotes,*.py",
			"/home/webdev/work/python/mynotes/apps,*.py",
			"/home/webdev/work/python/mynotes/apps,*.html",
			"/home/webdev/work/python/mynotes/apps*.html",
			"/home/webdev/work/python/mynotes/apps*.py",
			"/home/webdev/work/python/mynotes/apps/templates,*.css",
			"/home/webdev/work/python/mynotes/env/python3.5/lib/python3.5/site-packages/django/forms",
			"/home/webdev/work/python/mynotes/,*.html,/home/webdev/work/tmp/gentelella/production,*.t",
			"/home/webdev/work/python/mynotes/,*.html,/home/webdev/work/tmp/gentelella/production,*.*",
			"/home/webdev/work/python/mynotes/,*.css,/home/webdev/work/tmp/gentelella/production,*.*",
			"/home/webdev/work/python/mynotes/,*.css,/home/webdev/work/tmp/gentelella/production",
			"/home/webdev/work/python/mynotes/,*.css",
			"/home/webdev/work/python/mynotes/,*.html",
			"/home/webdev/work/python/mynotes/,*.css",
			"/home/webdev/work/python/mynotes/,*.py",
			"/home/webdev/work/python/mynotes/",
			"/home/webdev/work/python/mynotes/,*.py",
			"/home/webdev/work/python/mynotes/config,*.py",
			"/home/webdev/work/python/mytest/,*.py",
			"/home/webdev/work/python/mynotes/,*.py",
			"/home/webdev/work/python/mynotes/,*.*",
			"/home/webdev/work/python/mydrive/,*.*",
			"/home/webdev/work/python/mydrive/,*.js",
			"/home/webdev/work/python/mydrive/,*.py",
			"/home/webdev/work/python/mydrive/,*.*",
			"/home/webdev/work/python/mydrive/,*.py",
			"/home/webdev/work/python/mydrive/,*.js",
			"/home/webdev/work/python/mydrive/,*.css",
			"/home/webdev/work/python/mydrive/,*.js",
			"/home/webdev/work/python/mydrive/,*.*",
			"/home/webdev/work/python/mydrive/,*.html",
			"/home/webdev/work/python/mydrive/,*.css",
			"/home/webdev/work/python/mydrive/,*.py",
			"/home/webdev/work/python/mydrive/,*.js",
			"/home/webdev/work/python/mydrive/,*.py",
			"/home/webdev/work/python/mydrive/,*.js",
			"/home/webdev/work/python/mydrive/,*.py",
			"/home/webdev/work/python/mydrive/,*.js",
			"/home/webdev/work/python/mydrive/,*.py",
			"/home/webdev/work/python/mydrive/,*.js",
			"/home/webdev/work/python/mydrive/,*.css",
			"/home/webdev/work/python/mydrive/,*.js",
			"/home/webdev/work/python/mydrive/mydrive/,*.js",
			"/home/webdev/work/python/mydrive/mydrive/,*.py",
			"/home/webdev/work/python/mydrive/mydrive",
			"/home/webdev/django/project/apps/webged/static/ged/js,*.js",
			"/home/webdev/work/python/django/project/apps/,*.js",
			"/home/webdev/work/python/django/project/apps/",
			"/home/webdev/work/python/django/project/apps/ *.js",
			"/home/webdev/work/python/django/project/apps/**.js**",
			"/home/webdev/work/python/django/project/apps/*.js",
			"/home/webdev/work/python/django/project/apps/**.js",
			"/home/webdev/work/python/django/project/apps",
			"/home/webdev/work/python/django/project/apps,/home/webdev/work/python/django/env/python3.5/lib/python3.5/site-packages",
			"/home/webdev/work/python/django/project/apps",
			"/home/webdev/work/python/django/mysite/mysite"
		]
	},
	"find_state":
	{
		"case_sensitive": false,
		"find_history":
		[
			"ArchiveSerializer",
			"Archive",
			")\n",
			"FileStore",
			"weiwset",
			"CrawlerViewSet",
			"Archive",
			"data-id=\"login\"",
			"404",
			"uploader",
			"import",
			"Task",
			"webmarks.core",
			"users",
			"users.",
			"authentication.",
			"authentification.",
			"uploader.",
			"upload.",
			"storage.",
			"users.",
			"rest_api_auth",
			"auth",
			"Folder",
			"webmarks.users",
			"webmarks_users",
			"account.0001_initial",
			"\n        ",
			"USERNAME_FIELD",
			"USER_MODEL_USERNAME_FIELD",
			"()\n",
			"populate_username",
			"authentification",
			"User",
			"Calls Django logout",
			"Calls Django logout method and delete the Token object assigned to the current User object.",
			"get_app",
			"get_app ",
			"SocialApp",
			"sociallogin_from_response",
			"fb_complete_login",
			"ACCOUNT_EMAIL_VERIFICATION",
			"SOCIALACCOUNT_AUTO_SIGNUP",
			"login",
			"ADAPTER",
			"AUTHENTICATION_METHOD",
			"AuthenticationBackend",
			"create_token",
			"get_social_login",
			"SessionAuthentication",
			"google_login",
			"fb_complete_login",
			"FacebookLoginOrSignup\nFacebookLoginOrSignup",
			"AUTH_USER_MODEL",
			"FileUploader",
			"USER_NA",
			"Confirm E-mail Address",
			"\"\"\"\n",
			"REST_AUTH_REGISTER_SERIALIZERS",
			"db",
			",'",
			"HOST_NAME",
			"validate_email",
			"valid_email_or_none",
			"validate_email",
			"validators",
			"ALLAUTH_SETTING_GETTER",
			"ADAPTER",
			"LOGIN_ATTEMPTS_TIMEOUT",
			"ADAP",
			"stdlogger",
			"get_object_or_404",
			"HttpResponse",
			"JSONRenderer",
			"media",
			"Archive",
			"models.Archive",
			"Archive",
			"AggregateList",
			"ModelSerializer",
			"account_confirm_email",
			"apps.users",
			"Archive",
			"CustomListKeyConstructor",
			"Tag",
			"auth.",
			"auth",
			"webmarks.auth",
			"APPS_DIR",
			"apps.",
			"mywebmarks",
			"FilterSetMetaclass",
			"model",
			"StandardResultsSetPagination",
			"Media",
			"required",
			"Model",
			"HistoricalRecords",
			"histo",
			"mywebmarks",
			"DL",
			"/DT",
			"apps.taskapp",
			"apps.webmarks",
			"complete_login",
			"confirm_email",
			"respond_email_verification_sent",
			"account_email_verification_sent",
			"get_email_confirmation_redirect_url",
			"registration",
			"AuthenticationBackend",
			"allauth",
			"account_email_verification_sent",
			"account_confirm_email",
			"account_email_verification_sent",
			"account_confirm_email",
			"Note",
			"mynotes_tag",
			"mynotes",
			"mynote_tag",
			"mynotes",
			"NoteSerializer",
			"Note",
			"note",
			"Note",
			"             ",
			"user_cre_id",
			"client"
		],
		"highlight": true,
		"in_selection": false,
		"preserve_case": false,
		"regex": false,
		"replace_history":
		[
			"",
			"BookMark",
			"Archive",
			"CrawlResult",
			"mynotes:",
			"/mydrive/assets/images",
			"/",
			"/mydrive/assets/css/skell/",
			"/mydrive/assets/css/",
			"/mydrive/assets/js/",
			"/mydrive/",
			"",
			"/",
			"/static/",
			"drive",
			"mydrive/",
			"webdrive.",
			"backdrive.",
			"../../images/treeview",
			"",
			"notes"
		],
		"reverse": false,
		"show_context": true,
		"use_buffer2": true,
		"whole_word": true,
		"wrap": true
	},
	"groups":
	[
		{
			"selected": 2,
			"sheets":
			[
				{
					"buffer": 0,
					"file": "apps/webmarks/storage/models.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 763,
						"regions":
						{
						},
						"selection":
						[
							[
								763,
								763
							]
						],
						"settings":
						{
							"auto_complete_triggers":
							[
								{
									"characters": ".",
									"selector": "source.python - string - comment - constant.numeric"
								},
								{
									"characters": ".",
									"selector": "source.python - string - constant.numeric"
								}
							],
							"git_gutter_is_enabled": true,
							"syntax": "Packages/Djaneiro/Syntaxes/Python Django.tmLanguage",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 7,
					"type": "text"
				},
				{
					"buffer": 1,
					"file": "apps/webmarks/storage/serializers.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 300,
						"regions":
						{
						},
						"selection":
						[
							[
								300,
								300
							]
						],
						"settings":
						{
							"git_gutter_is_enabled": true,
							"syntax": "Packages/Djaneiro/Syntaxes/Python Django.tmLanguage"
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 5,
					"type": "text"
				},
				{
					"buffer": 2,
					"file": "apps/webmarks/bookmarks/viewsets.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 6065,
						"regions":
						{
						},
						"selection":
						[
							[
								880,
								880
							]
						],
						"settings":
						{
							"auto_complete_triggers":
							[
								{
									"characters": ".",
									"selector": "source.python - string - comment - constant.numeric"
								},
								{
									"characters": ".",
									"selector": "source.python - string - constant.numeric"
								}
							],
							"git_gutter_is_enabled": true,
							"syntax": "Packages/Djaneiro/Syntaxes/Python Django.tmLanguage",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": -0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 0,
					"type": "text"
				},
				{
					"buffer": 3,
					"file": "apps/webmarks/storage/viewsets.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 2098,
						"regions":
						{
						},
						"selection":
						[
							[
								1119,
								1119
							]
						],
						"settings":
						{
							"auto_complete_triggers":
							[
								{
									"characters": ".",
									"selector": "source.python - string - comment - constant.numeric"
								},
								{
									"characters": ".",
									"selector": "source.python - string - constant.numeric"
								}
							],
							"git_gutter_is_enabled": true,
							"syntax": "Packages/Djaneiro/Syntaxes/Python Django.tmLanguage",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": -0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 4,
					"type": "text"
				},
				{
					"buffer": 4,
					"file": "apps/webmarks/storage/urls.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 383,
						"regions":
						{
						},
						"selection":
						[
							[
								383,
								383
							]
						],
						"settings":
						{
							"git_gutter_is_enabled": true,
							"syntax": "Packages/Djaneiro/Syntaxes/Python Django.tmLanguage"
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 2,
					"type": "text"
				},
				{
					"buffer": 5,
					"file": "env/lib/python3.5/site-packages/compressor/base.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 14075,
						"regions":
						{
						},
						"selection":
						[
							[
								1859,
								1859
							]
						],
						"settings":
						{
							"git_gutter_is_enabled": true,
							"syntax": "Packages/Djaneiro/Syntaxes/Python Django.tmLanguage",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 478.0,
						"zoom_level": 1.0
					},
					"stack_index": 3,
					"type": "text"
				},
				{
					"buffer": 6,
					"file": "apps/webmarks/storage/storages.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 1561,
						"regions":
						{
						},
						"selection":
						[
							[
								358,
								358
							]
						],
						"settings":
						{
							"auto_complete_triggers":
							[
								{
									"characters": ".",
									"selector": "source.python - string - comment - constant.numeric"
								},
								{
									"characters": ".",
									"selector": "source.python - string - constant.numeric"
								}
							],
							"git_gutter_is_enabled": true,
							"syntax": "Packages/Djaneiro/Syntaxes/Python Django.tmLanguage",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 6,
					"type": "text"
				},
				{
					"buffer": 7,
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 127968,
						"regions":
						{
							"match":
							{
								"flags": 112,
								"regions":
								[
									[
										203,
										210
									],
									[
										380,
										387
									],
									[
										627,
										634
									],
									[
										637,
										644
									],
									[
										747,
										754
									],
									[
										807,
										814
									],
									[
										953,
										960
									],
									[
										1041,
										1048
									],
									[
										1291,
										1298
									],
									[
										1614,
										1621
									],
									[
										1970,
										1977
									],
									[
										2151,
										2158
									],
									[
										2255,
										2262
									],
									[
										2325,
										2332
									],
									[
										2425,
										2432
									],
									[
										2485,
										2492
									],
									[
										2603,
										2610
									],
									[
										2638,
										2645
									],
									[
										2751,
										2758
									],
									[
										2823,
										2830
									],
									[
										3035,
										3042
									],
									[
										3083,
										3090
									],
									[
										3206,
										3213
									],
									[
										3450,
										3457
									],
									[
										3630,
										3637
									],
									[
										3852,
										3859
									],
									[
										4029,
										4036
									],
									[
										4321,
										4328
									],
									[
										4482,
										4489
									],
									[
										4645,
										4652
									],
									[
										4724,
										4731
									],
									[
										4892,
										4899
									],
									[
										5003,
										5010
									],
									[
										5085,
										5092
									],
									[
										5295,
										5302
									],
									[
										5545,
										5552
									],
									[
										5752,
										5759
									],
									[
										5925,
										5932
									],
									[
										5983,
										5990
									],
									[
										6072,
										6079
									],
									[
										6195,
										6202
									],
									[
										6547,
										6554
									],
									[
										6808,
										6815
									],
									[
										7302,
										7309
									],
									[
										7772,
										7779
									],
									[
										8033,
										8040
									],
									[
										8336,
										8343
									],
									[
										8686,
										8693
									],
									[
										8916,
										8923
									],
									[
										9014,
										9021
									],
									[
										9186,
										9193
									],
									[
										9242,
										9249
									],
									[
										9599,
										9606
									],
									[
										9940,
										9947
									],
									[
										10196,
										10203
									],
									[
										10462,
										10469
									],
									[
										10683,
										10690
									],
									[
										10923,
										10930
									],
									[
										11222,
										11229
									],
									[
										11368,
										11375
									],
									[
										11520,
										11527
									],
									[
										11530,
										11537
									],
									[
										11776,
										11783
									],
									[
										12062,
										12069
									],
									[
										12125,
										12132
									],
									[
										12306,
										12313
									],
									[
										12589,
										12596
									],
									[
										12632,
										12639
									],
									[
										12805,
										12812
									],
									[
										13088,
										13095
									],
									[
										13334,
										13341
									],
									[
										13554,
										13561
									],
									[
										13706,
										13713
									],
									[
										13817,
										13824
									],
									[
										13975,
										13982
									],
									[
										14244,
										14251
									],
									[
										14442,
										14449
									],
									[
										14654,
										14661
									],
									[
										14777,
										14784
									],
									[
										14965,
										14972
									],
									[
										15175,
										15182
									],
									[
										15296,
										15303
									],
									[
										15458,
										15465
									],
									[
										15644,
										15651
									],
									[
										15847,
										15854
									],
									[
										16032,
										16039
									],
									[
										16247,
										16254
									],
									[
										16469,
										16476
									],
									[
										16857,
										16864
									],
									[
										17083,
										17090
									],
									[
										17266,
										17273
									],
									[
										17607,
										17614
									],
									[
										17933,
										17940
									],
									[
										18137,
										18144
									],
									[
										18327,
										18334
									],
									[
										18698,
										18705
									],
									[
										19118,
										19125
									],
									[
										19213,
										19220
									],
									[
										19437,
										19444
									],
									[
										19655,
										19662
									],
									[
										19858,
										19865
									],
									[
										19930,
										19937
									],
									[
										19962,
										19969
									],
									[
										20180,
										20187
									],
									[
										20522,
										20529
									],
									[
										20738,
										20745
									],
									[
										20972,
										20979
									],
									[
										21071,
										21078
									],
									[
										21229,
										21236
									],
									[
										21375,
										21382
									],
									[
										21587,
										21594
									],
									[
										21665,
										21672
									],
									[
										21931,
										21938
									],
									[
										22187,
										22194
									],
									[
										22505,
										22512
									],
									[
										22809,
										22816
									],
									[
										23092,
										23099
									],
									[
										23278,
										23285
									],
									[
										23704,
										23711
									],
									[
										23920,
										23927
									],
									[
										24277,
										24284
									],
									[
										24557,
										24564
									],
									[
										24690,
										24697
									],
									[
										24882,
										24889
									],
									[
										25101,
										25108
									],
									[
										25235,
										25242
									],
									[
										25427,
										25434
									],
									[
										25795,
										25802
									],
									[
										26132,
										26139
									],
									[
										26185,
										26192
									],
									[
										26216,
										26223
									],
									[
										26414,
										26421
									],
									[
										26806,
										26813
									],
									[
										26858,
										26865
									],
									[
										26933,
										26940
									],
									[
										27036,
										27043
									],
									[
										27127,
										27134
									],
									[
										27301,
										27308
									],
									[
										27353,
										27360
									],
									[
										27709,
										27716
									],
									[
										28005,
										28012
									],
									[
										28304,
										28311
									],
									[
										28332,
										28339
									],
									[
										28378,
										28385
									],
									[
										28429,
										28436
									],
									[
										28554,
										28561
									],
									[
										28630,
										28637
									],
									[
										28850,
										28857
									],
									[
										28913,
										28920
									],
									[
										28945,
										28952
									],
									[
										28986,
										28993
									],
									[
										29017,
										29024
									],
									[
										29114,
										29121
									],
									[
										29352,
										29359
									],
									[
										29375,
										29382
									],
									[
										29680,
										29687
									],
									[
										29802,
										29809
									],
									[
										30112,
										30119
									],
									[
										30446,
										30453
									],
									[
										30754,
										30761
									],
									[
										30919,
										30926
									],
									[
										31123,
										31130
									],
									[
										31264,
										31271
									],
									[
										31403,
										31410
									],
									[
										31574,
										31581
									],
									[
										31614,
										31621
									],
									[
										31690,
										31697
									],
									[
										31775,
										31782
									],
									[
										31819,
										31826
									],
									[
										31893,
										31900
									],
									[
										31927,
										31934
									],
									[
										32080,
										32087
									],
									[
										32140,
										32147
									],
									[
										32344,
										32351
									],
									[
										32532,
										32539
									],
									[
										32626,
										32633
									],
									[
										32690,
										32697
									],
									[
										32875,
										32882
									],
									[
										32993,
										33000
									],
									[
										33074,
										33081
									],
									[
										33118,
										33125
									],
									[
										33346,
										33353
									],
									[
										33401,
										33408
									],
									[
										33581,
										33588
									],
									[
										33618,
										33625
									],
									[
										33812,
										33819
									],
									[
										33920,
										33927
									],
									[
										34205,
										34212
									],
									[
										34433,
										34440
									],
									[
										34711,
										34718
									],
									[
										34784,
										34791
									],
									[
										34842,
										34849
									],
									[
										35075,
										35082
									],
									[
										35223,
										35230
									],
									[
										35263,
										35270
									],
									[
										35292,
										35299
									],
									[
										35438,
										35445
									],
									[
										35527,
										35534
									],
									[
										35561,
										35568
									],
									[
										35610,
										35617
									],
									[
										35737,
										35744
									],
									[
										35860,
										35867
									],
									[
										35963,
										35970
									],
									[
										36032,
										36039
									],
									[
										36110,
										36117
									],
									[
										36285,
										36292
									],
									[
										36521,
										36528
									],
									[
										36561,
										36568
									],
									[
										36736,
										36743
									],
									[
										37046,
										37053
									],
									[
										37180,
										37187
									],
									[
										37319,
										37326
									],
									[
										37440,
										37447
									],
									[
										37652,
										37659
									],
									[
										37943,
										37950
									],
									[
										38036,
										38043
									],
									[
										38116,
										38123
									],
									[
										38210,
										38217
									],
									[
										38287,
										38294
									],
									[
										38331,
										38338
									],
									[
										38360,
										38367
									],
									[
										38411,
										38418
									],
									[
										38509,
										38516
									],
									[
										38702,
										38709
									],
									[
										38943,
										38950
									],
									[
										39013,
										39020
									],
									[
										39330,
										39337
									],
									[
										39665,
										39672
									],
									[
										39946,
										39953
									],
									[
										40272,
										40279
									],
									[
										40502,
										40509
									],
									[
										40753,
										40760
									],
									[
										40983,
										40990
									],
									[
										41238,
										41245
									],
									[
										41417,
										41424
									],
									[
										41609,
										41616
									],
									[
										41955,
										41962
									],
									[
										42264,
										42271
									],
									[
										42303,
										42310
									],
									[
										42610,
										42617
									],
									[
										42726,
										42733
									],
									[
										43110,
										43117
									],
									[
										43393,
										43400
									],
									[
										43580,
										43587
									],
									[
										43691,
										43698
									],
									[
										43957,
										43964
									],
									[
										43998,
										44005
									],
									[
										44045,
										44052
									],
									[
										44347,
										44354
									],
									[
										44576,
										44583
									],
									[
										44648,
										44655
									],
									[
										44680,
										44687
									],
									[
										44910,
										44917
									],
									[
										45130,
										45137
									],
									[
										45202,
										45209
									],
									[
										45234,
										45241
									],
									[
										45423,
										45430
									],
									[
										45536,
										45543
									],
									[
										45752,
										45759
									],
									[
										45924,
										45931
									],
									[
										46058,
										46065
									],
									[
										46265,
										46272
									],
									[
										46476,
										46483
									],
									[
										46612,
										46619
									],
									[
										46644,
										46651
									],
									[
										46903,
										46910
									],
									[
										47103,
										47110
									],
									[
										47135,
										47142
									],
									[
										47285,
										47292
									],
									[
										47424,
										47431
									],
									[
										47456,
										47463
									],
									[
										47593,
										47600
									],
									[
										47659,
										47666
									],
									[
										47926,
										47933
									],
									[
										48110,
										48117
									],
									[
										48338,
										48345
									],
									[
										48456,
										48463
									],
									[
										48768,
										48775
									],
									[
										49098,
										49105
									],
									[
										49391,
										49398
									],
									[
										49648,
										49655
									],
									[
										49953,
										49960
									],
									[
										50385,
										50392
									],
									[
										50661,
										50668
									],
									[
										50907,
										50914
									],
									[
										50999,
										51006
									],
									[
										51389,
										51396
									],
									[
										51604,
										51611
									],
									[
										51651,
										51658
									],
									[
										51855,
										51862
									],
									[
										52034,
										52041
									],
									[
										52143,
										52150
									],
									[
										52160,
										52167
									],
									[
										52184,
										52191
									],
									[
										52238,
										52245
									],
									[
										52325,
										52332
									],
									[
										52562,
										52569
									],
									[
										52827,
										52834
									],
									[
										52964,
										52971
									],
									[
										53166,
										53173
									],
									[
										53512,
										53519
									],
									[
										53772,
										53779
									],
									[
										53991,
										53998
									],
									[
										54285,
										54292
									],
									[
										54341,
										54348
									],
									[
										54693,
										54700
									],
									[
										55039,
										55046
									],
									[
										55369,
										55376
									],
									[
										55806,
										55813
									],
									[
										56388,
										56395
									],
									[
										56775,
										56782
									],
									[
										57290,
										57297
									],
									[
										57472,
										57479
									],
									[
										57519,
										57526
									],
									[
										57753,
										57760
									],
									[
										58042,
										58049
									],
									[
										58461,
										58468
									],
									[
										58752,
										58759
									],
									[
										58932,
										58939
									],
									[
										59154,
										59161
									],
									[
										59331,
										59338
									],
									[
										59623,
										59630
									],
									[
										59784,
										59791
									],
									[
										59947,
										59954
									],
									[
										60026,
										60033
									],
									[
										60194,
										60201
									],
									[
										60305,
										60312
									],
									[
										60387,
										60394
									],
									[
										60597,
										60604
									],
									[
										60847,
										60854
									],
									[
										61054,
										61061
									],
									[
										61227,
										61234
									],
									[
										61285,
										61292
									],
									[
										61374,
										61381
									],
									[
										61497,
										61504
									],
									[
										61849,
										61856
									],
									[
										62154,
										62161
									],
									[
										62354,
										62361
									],
									[
										62704,
										62711
									],
									[
										63029,
										63036
									],
									[
										63109,
										63116
									],
									[
										63470,
										63477
									],
									[
										63598,
										63605
									],
									[
										63758,
										63765
									],
									[
										64007,
										64014
									],
									[
										64252,
										64259
									],
									[
										64520,
										64527
									],
									[
										64780,
										64787
									],
									[
										65030,
										65037
									],
									[
										65246,
										65253
									],
									[
										65334,
										65341
									],
									[
										65537,
										65544
									],
									[
										65643,
										65650
									],
									[
										65899,
										65906
									],
									[
										66026,
										66033
									],
									[
										66362,
										66369
									],
									[
										66532,
										66539
									],
									[
										66819,
										66826
									],
									[
										67005,
										67012
									],
									[
										67388,
										67395
									],
									[
										67536,
										67543
									],
									[
										67548,
										67555
									],
									[
										67800,
										67807
									],
									[
										68014,
										68021
									],
									[
										68117,
										68124
									],
									[
										68397,
										68404
									],
									[
										68710,
										68717
									],
									[
										69026,
										69033
									],
									[
										69423,
										69430
									],
									[
										69691,
										69698
									],
									[
										69926,
										69933
									],
									[
										70180,
										70187
									],
									[
										70399,
										70406
									],
									[
										70633,
										70640
									],
									[
										70742,
										70749
									],
									[
										70921,
										70928
									],
									[
										71237,
										71244
									],
									[
										71467,
										71474
									],
									[
										71739,
										71746
									],
									[
										72165,
										72172
									],
									[
										72456,
										72463
									],
									[
										72665,
										72672
									],
									[
										73020,
										73027
									],
									[
										73371,
										73378
									],
									[
										73393,
										73400
									],
									[
										73442,
										73449
									],
									[
										73725,
										73732
									],
									[
										73887,
										73894
									],
									[
										74181,
										74188
									],
									[
										74365,
										74372
									],
									[
										74466,
										74473
									],
									[
										74611,
										74618
									],
									[
										74718,
										74725
									],
									[
										75012,
										75019
									],
									[
										75187,
										75194
									],
									[
										75262,
										75269
									],
									[
										75290,
										75297
									],
									[
										75511,
										75518
									],
									[
										75866,
										75873
									],
									[
										75984,
										75991
									],
									[
										76495,
										76502
									],
									[
										76705,
										76712
									],
									[
										76935,
										76942
									],
									[
										77163,
										77170
									],
									[
										77368,
										77375
									],
									[
										77518,
										77525
									],
									[
										77612,
										77619
									],
									[
										77774,
										77781
									],
									[
										78137,
										78144
									],
									[
										78492,
										78499
									],
									[
										78761,
										78768
									],
									[
										78995,
										79002
									],
									[
										79089,
										79096
									],
									[
										79419,
										79426
									],
									[
										79738,
										79745
									],
									[
										80025,
										80032
									],
									[
										80232,
										80239
									],
									[
										80493,
										80500
									],
									[
										80723,
										80730
									],
									[
										81150,
										81157
									],
									[
										81489,
										81496
									],
									[
										81756,
										81763
									],
									[
										82034,
										82041
									],
									[
										82378,
										82385
									],
									[
										82710,
										82717
									],
									[
										82970,
										82977
									],
									[
										83314,
										83321
									],
									[
										83766,
										83773
									],
									[
										83996,
										84003
									],
									[
										84160,
										84167
									],
									[
										84399,
										84406
									],
									[
										84702,
										84709
									],
									[
										85161,
										85168
									],
									[
										85371,
										85378
									],
									[
										85599,
										85606
									],
									[
										85827,
										85834
									],
									[
										86032,
										86039
									],
									[
										86180,
										86187
									],
									[
										86274,
										86281
									],
									[
										86436,
										86443
									],
									[
										86780,
										86787
									],
									[
										87083,
										87090
									],
									[
										87415,
										87422
									],
									[
										87550,
										87557
									],
									[
										87730,
										87737
									],
									[
										88135,
										88142
									],
									[
										88471,
										88478
									],
									[
										88780,
										88787
									],
									[
										88969,
										88976
									],
									[
										89263,
										89270
									],
									[
										89695,
										89702
									],
									[
										89866,
										89873
									],
									[
										90152,
										90159
									],
									[
										90298,
										90305
									],
									[
										90555,
										90562
									],
									[
										90896,
										90903
									],
									[
										91066,
										91073
									],
									[
										91359,
										91366
									],
									[
										91587,
										91594
									],
									[
										91996,
										92003
									],
									[
										92113,
										92120
									],
									[
										92430,
										92437
									],
									[
										92541,
										92548
									],
									[
										92918,
										92925
									],
									[
										93144,
										93151
									],
									[
										93332,
										93339
									],
									[
										93455,
										93462
									],
									[
										93690,
										93697
									],
									[
										93931,
										93938
									],
									[
										94103,
										94110
									],
									[
										94426,
										94433
									],
									[
										94735,
										94742
									],
									[
										94939,
										94946
									],
									[
										95144,
										95151
									],
									[
										95426,
										95433
									],
									[
										95647,
										95654
									],
									[
										95989,
										95996
									],
									[
										96258,
										96265
									],
									[
										96562,
										96569
									],
									[
										96829,
										96836
									],
									[
										97112,
										97119
									],
									[
										97334,
										97341
									],
									[
										97634,
										97641
									],
									[
										97858,
										97865
									],
									[
										98137,
										98144
									],
									[
										98495,
										98502
									],
									[
										98548,
										98555
									],
									[
										98886,
										98893
									],
									[
										99148,
										99155
									],
									[
										99347,
										99354
									],
									[
										99615,
										99622
									],
									[
										99965,
										99972
									],
									[
										100290,
										100297
									],
									[
										100370,
										100377
									],
									[
										100731,
										100738
									],
									[
										100859,
										100866
									],
									[
										101019,
										101026
									],
									[
										101268,
										101275
									],
									[
										101513,
										101520
									],
									[
										101779,
										101786
									],
									[
										102039,
										102046
									],
									[
										102293,
										102300
									],
									[
										102543,
										102550
									],
									[
										102759,
										102766
									],
									[
										102847,
										102854
									],
									[
										103050,
										103057
									],
									[
										103156,
										103163
									],
									[
										103412,
										103419
									],
									[
										103539,
										103546
									],
									[
										103875,
										103882
									],
									[
										104046,
										104053
									],
									[
										104336,
										104343
									],
									[
										104522,
										104529
									],
									[
										104905,
										104912
									],
									[
										105054,
										105061
									],
									[
										105066,
										105073
									],
									[
										105318,
										105325
									],
									[
										105539,
										105546
									],
									[
										105642,
										105649
									],
									[
										105946,
										105953
									],
									[
										106283,
										106290
									],
									[
										106599,
										106606
									],
									[
										106999,
										107006
									],
									[
										107267,
										107274
									],
									[
										107517,
										107524
									],
									[
										107771,
										107778
									],
									[
										107990,
										107997
									],
									[
										108224,
										108231
									],
									[
										108333,
										108340
									],
									[
										108531,
										108538
									],
									[
										108847,
										108854
									],
									[
										109077,
										109084
									],
									[
										109311,
										109318
									],
									[
										109408,
										109415
									],
									[
										109601,
										109608
									],
									[
										109778,
										109785
									],
									[
										110083,
										110090
									],
									[
										110313,
										110320
									],
									[
										110411,
										110418
									],
									[
										110583,
										110590
									],
									[
										110639,
										110646
									],
									[
										110989,
										110996
									],
									[
										111330,
										111337
									],
									[
										111586,
										111593
									],
									[
										111852,
										111859
									],
									[
										112073,
										112080
									],
									[
										112313,
										112320
									],
									[
										112605,
										112612
									],
									[
										112751,
										112758
									],
									[
										112903,
										112910
									],
									[
										112913,
										112920
									],
									[
										113159,
										113166
									],
									[
										113445,
										113452
									],
									[
										113508,
										113515
									],
									[
										113689,
										113696
									],
									[
										113972,
										113979
									],
									[
										114015,
										114022
									],
									[
										114188,
										114195
									],
									[
										114471,
										114478
									],
									[
										114717,
										114724
									],
									[
										114937,
										114944
									],
									[
										115089,
										115096
									],
									[
										115200,
										115207
									],
									[
										115358,
										115365
									],
									[
										115627,
										115634
									],
									[
										115825,
										115832
									],
									[
										116037,
										116044
									],
									[
										116160,
										116167
									],
									[
										116348,
										116355
									],
									[
										116558,
										116565
									],
									[
										116679,
										116686
									],
									[
										116841,
										116848
									],
									[
										117027,
										117034
									],
									[
										117230,
										117237
									],
									[
										117415,
										117422
									],
									[
										117630,
										117637
									],
									[
										117852,
										117859
									],
									[
										118233,
										118240
									],
									[
										118459,
										118466
									],
									[
										118642,
										118649
									],
									[
										118980,
										118987
									],
									[
										119210,
										119217
									],
									[
										119308,
										119315
									],
									[
										119480,
										119487
									],
									[
										119536,
										119543
									],
									[
										119863,
										119870
									],
									[
										120204,
										120211
									],
									[
										120460,
										120467
									],
									[
										120726,
										120733
									],
									[
										120947,
										120954
									],
									[
										121187,
										121194
									],
									[
										121456,
										121463
									],
									[
										121602,
										121609
									],
									[
										121754,
										121761
									],
									[
										121764,
										121771
									],
									[
										122010,
										122017
									],
									[
										122296,
										122303
									],
									[
										122359,
										122366
									],
									[
										122540,
										122547
									],
									[
										122823,
										122830
									],
									[
										122866,
										122873
									],
									[
										123039,
										123046
									],
									[
										123322,
										123329
									],
									[
										123568,
										123575
									],
									[
										123788,
										123795
									],
									[
										123940,
										123947
									],
									[
										124051,
										124058
									],
									[
										124209,
										124216
									],
									[
										124478,
										124485
									],
									[
										124676,
										124683
									],
									[
										124888,
										124895
									],
									[
										125011,
										125018
									],
									[
										125199,
										125206
									],
									[
										125409,
										125416
									],
									[
										125530,
										125537
									],
									[
										125692,
										125699
									],
									[
										125878,
										125885
									],
									[
										126081,
										126088
									],
									[
										126266,
										126273
									],
									[
										126481,
										126488
									],
									[
										126703,
										126710
									],
									[
										127061,
										127068
									],
									[
										127287,
										127294
									],
									[
										127470,
										127477
									],
									[
										127866,
										127883
									]
								],
								"scope": ""
							}
						},
						"selection":
						[
							[
								127874,
								127874
							]
						],
						"settings":
						{
							"default_dir": "/home/webdev/work/python/mywebmarks-backend",
							"detect_indentation": false,
							"git_gutter_is_enabled": false,
							"line_numbers": false,
							"output_tag": 2,
							"result_base_dir": "",
							"result_file_regex": "^([A-Za-z\\\\/<].*):$",
							"result_line_regex": "^ +([0-9]+):",
							"scroll_past_end": true,
							"syntax": "Packages/Default/Find Results.hidden-tmLanguage"
						},
						"translation.x": 0.0,
						"translation.y": 55043.0,
						"zoom_level": 1.0
					},
					"stack_index": 1,
					"type": "text"
				}
			]
		}
	],
	"incremental_find":
	{
		"height": 27.0
	},
	"input":
	{
		"height": 35.0
	},
	"layout":
	{
		"cells":
		[
			[
				0,
				0,
				1,
				1
			]
		],
		"cols":
		[
			0.0,
			1.0
		],
		"rows":
		[
			0.0,
			1.0
		]
	},
	"menu_visible": true,
	"output.exec":
	{
		"height": 118.0
	},
	"output.find_results":
	{
		"height": 0.0
	},
	"pinned_build_system": "Packages/Virtualenv/Python + Virtualenv.sublime-build",
	"project": "webmarks.sublime-project",
	"replace":
	{
		"height": 68.0
	},
	"save_all_on_build": true,
	"select_file":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
			[
				"/managers.py",
				"apps/mywebmarks/managers.py"
			],
			[
				"index",
				"apps/templates/mynotes/index.html"
			],
			[
				"login",
				"apps/templates/account/login.html"
			],
			[
				"models",
				"apps/mynotes/models.py"
			],
			[
				"form",
				"apps/mynotes/forms.py"
			],
			[
				"mode",
				"apps/mynotes/models.py"
			],
			[
				"base",
				"apps/templates/base.html"
			],
			[
				"nprogress.j",
				"apps/static/vendors/nprogress/nprogress.js"
			],
			[
				"select2multiple",
				"staticfiles/vendors/select2/tests/selection/multiple-tests.js"
			],
			[
				"provider_list",
				"env/python3.5/lib/python3.5/site-packages/allauth/templates/socialaccount/snippets/provider_list.html"
			],
			[
				"config.py",
				"env/python3.5/lib/python3.5/site-packages/django/apps/config.py"
			],
			[
				"admin",
				"apps/drive/admin.py"
			],
			[
				"doc",
				"apps/mydrive/static/mydrive/js/app/documents/documents.ctrl.js"
			],
			[
				"index.html",
				"mysite/templates/index.html"
			],
			[
				"inde",
				"apps/svi-front-frontend/app/index.html"
			],
			[
				"upload",
				"apps/webged/templates/ged/partials/uploads.html"
			],
			[
				"uploads",
				"apps/webged/templates/ged/partials/uploads.html"
			],
			[
				"fileuplo",
				"apps/svi-front-frontend/app/bower_components/angular-file-upload/angular-file-upload.js"
			],
			[
				"mo",
				"apps/ged/models.py"
			],
			[
				"sett",
				"mysite/settings.py"
			],
			[
				"app",
				"apps/webged/static/ged/js/app/app.js"
			],
			[
				"ind",
				"apps/webged/templates/ged/index.html"
			],
			[
				"setting",
				"mysite/settings.py"
			],
			[
				"i",
				"apps/webged/templates/ged/index.html"
			],
			[
				"log",
				"apps/webged/static/ged/js/app/login/login.ctrl.js"
			],
			[
				"in",
				"apps/webged/templates/ged/index.html"
			],
			[
				"serialis",
				"apps/ged/serializers.py"
			],
			[
				"m",
				"apps/ged/models.py"
			],
			[
				"file",
				"apps/webged/templates/ged/partials/fileplan.html"
			],
			[
				"u",
				"apps/webged/templates/ged/partials/upload.html"
			],
			[
				"fil",
				"apps/webged/templates/ged/partials/fileplan.html"
			],
			[
				"se",
				"mysite/settings.py"
			],
			[
				"up",
				"apps/webged/templates/ged/partials/upload.html"
			],
			[
				"arc",
				"apps/webged/templates/ged/partials/archives.html"
			],
			[
				"uplo",
				"apps/webged/templates/ged/partials/upload.html"
			],
			[
				"basketviewset",
				"env/python3.5/lib/python3.5/site-packages/rest_framework/viewsets.py"
			]
		],
		"width": 0.0
	},
	"select_project":
	{
		"height": 550.0,
		"last_filter": "",
		"selected_items":
		[
			[
				"",
				"~/.config/sublime-text-3/Packages/django.sublime-workspace"
			]
		],
		"width": 418.0
	},
	"select_symbol":
	{
		"height": 432.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 586.0
	},
	"selected_group": 0,
	"settings":
	{
	},
	"show_minimap": false,
	"show_open_files": true,
	"show_tabs": true,
	"side_bar_visible": true,
	"side_bar_width": 361.0,
	"status_bar_visible": true,
	"template_settings":
	{
	}
}
